{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import lightning as L\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import BatchSizeFinder, LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import NeptuneLogger\n",
    "import neptune\n",
    "import os\n",
    "import torch.autograd.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and PreProcessing the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_totl,_time</th>\n",
       "      <th>Vtrue,_ktgs</th>\n",
       "      <th>pitch,__deg</th>\n",
       "      <th>_roll,__deg</th>\n",
       "      <th>hding,_true</th>\n",
       "      <th>__lat,__deg</th>\n",
       "      <th>__lon,__deg</th>\n",
       "      <th>___CG,ftMSL</th>\n",
       "      <th>____X,____m</th>\n",
       "      <th>____Y,____m</th>\n",
       "      <th>____Z,____m</th>\n",
       "      <th>___vX,__m/s</th>\n",
       "      <th>___vY,__m/s</th>\n",
       "      <th>___vZ,__m/s</th>\n",
       "      <th>_elev,stick</th>\n",
       "      <th>ailrn,stick</th>\n",
       "      <th>ruddr,stick</th>\n",
       "      <th>thro1,engin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.48427</td>\n",
       "      <td>103.49908</td>\n",
       "      <td>0.07651</td>\n",
       "      <td>-0.00486</td>\n",
       "      <td>316.95850</td>\n",
       "      <td>46.56116</td>\n",
       "      <td>-122.69409</td>\n",
       "      <td>8150.02539</td>\n",
       "      <td>23464.83203</td>\n",
       "      <td>2437.26929</td>\n",
       "      <td>-6846.28711</td>\n",
       "      <td>-36.49474</td>\n",
       "      <td>-0.21043</td>\n",
       "      <td>-38.77045</td>\n",
       "      <td>-0.04573</td>\n",
       "      <td>0.00032</td>\n",
       "      <td>-0.00179</td>\n",
       "      <td>0.62949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.60311</td>\n",
       "      <td>103.48605</td>\n",
       "      <td>0.33557</td>\n",
       "      <td>-0.02232</td>\n",
       "      <td>316.97202</td>\n",
       "      <td>46.56120</td>\n",
       "      <td>-122.69415</td>\n",
       "      <td>8149.85596</td>\n",
       "      <td>23460.49609</td>\n",
       "      <td>2437.22852</td>\n",
       "      <td>-6850.89453</td>\n",
       "      <td>-36.49013</td>\n",
       "      <td>-0.44140</td>\n",
       "      <td>-38.76478</td>\n",
       "      <td>-0.06844</td>\n",
       "      <td>-0.00653</td>\n",
       "      <td>-0.00463</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.71961</td>\n",
       "      <td>103.43369</td>\n",
       "      <td>0.62848</td>\n",
       "      <td>-0.03600</td>\n",
       "      <td>316.98975</td>\n",
       "      <td>46.56124</td>\n",
       "      <td>-122.69421</td>\n",
       "      <td>8149.62158</td>\n",
       "      <td>23456.24609</td>\n",
       "      <td>2437.16772</td>\n",
       "      <td>-6855.40918</td>\n",
       "      <td>-36.47029</td>\n",
       "      <td>-0.57554</td>\n",
       "      <td>-38.74413</td>\n",
       "      <td>-0.05645</td>\n",
       "      <td>-0.00832</td>\n",
       "      <td>-0.00633</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.80210</td>\n",
       "      <td>103.37489</td>\n",
       "      <td>0.83224</td>\n",
       "      <td>-0.04432</td>\n",
       "      <td>317.00247</td>\n",
       "      <td>46.56127</td>\n",
       "      <td>-122.69424</td>\n",
       "      <td>8149.43262</td>\n",
       "      <td>23453.23828</td>\n",
       "      <td>2437.11768</td>\n",
       "      <td>-6858.60400</td>\n",
       "      <td>-36.44852</td>\n",
       "      <td>-0.62677</td>\n",
       "      <td>-38.72172</td>\n",
       "      <td>-0.04408</td>\n",
       "      <td>-0.00867</td>\n",
       "      <td>-0.00709</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.89681</td>\n",
       "      <td>103.29092</td>\n",
       "      <td>1.05690</td>\n",
       "      <td>-0.05146</td>\n",
       "      <td>317.01611</td>\n",
       "      <td>46.56130</td>\n",
       "      <td>-122.69429</td>\n",
       "      <td>8149.20410</td>\n",
       "      <td>23449.78711</td>\n",
       "      <td>2437.05688</td>\n",
       "      <td>-6862.26953</td>\n",
       "      <td>-36.41737</td>\n",
       "      <td>-0.65032</td>\n",
       "      <td>-38.68958</td>\n",
       "      <td>-0.03029</td>\n",
       "      <td>-0.00876</td>\n",
       "      <td>-0.00772</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7790</th>\n",
       "      <td>677.01807</td>\n",
       "      <td>102.64950</td>\n",
       "      <td>5.03510</td>\n",
       "      <td>-15.52756</td>\n",
       "      <td>92.21129</td>\n",
       "      <td>46.76450</td>\n",
       "      <td>-122.64340</td>\n",
       "      <td>10524.41309</td>\n",
       "      <td>27253.54688</td>\n",
       "      <td>3081.13818</td>\n",
       "      <td>-29478.54102</td>\n",
       "      <td>52.76324</td>\n",
       "      <td>2.18193</td>\n",
       "      <td>2.32113</td>\n",
       "      <td>0.01481</td>\n",
       "      <td>-0.03281</td>\n",
       "      <td>-0.00584</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7791</th>\n",
       "      <td>677.11859</td>\n",
       "      <td>102.61120</td>\n",
       "      <td>5.03769</td>\n",
       "      <td>-15.75969</td>\n",
       "      <td>91.90834</td>\n",
       "      <td>46.76450</td>\n",
       "      <td>-122.64333</td>\n",
       "      <td>10525.20117</td>\n",
       "      <td>27258.84961</td>\n",
       "      <td>3081.35693</td>\n",
       "      <td>-29478.32422</td>\n",
       "      <td>52.75458</td>\n",
       "      <td>2.17173</td>\n",
       "      <td>2.05556</td>\n",
       "      <td>0.01505</td>\n",
       "      <td>-0.03179</td>\n",
       "      <td>-0.00577</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7792</th>\n",
       "      <td>677.21912</td>\n",
       "      <td>102.57314</td>\n",
       "      <td>5.04044</td>\n",
       "      <td>-15.98804</td>\n",
       "      <td>91.60071</td>\n",
       "      <td>46.76449</td>\n",
       "      <td>-122.64326</td>\n",
       "      <td>10525.98730</td>\n",
       "      <td>27264.15039</td>\n",
       "      <td>3081.57471</td>\n",
       "      <td>-29478.13281</td>\n",
       "      <td>52.74484</td>\n",
       "      <td>2.16175</td>\n",
       "      <td>1.78573</td>\n",
       "      <td>0.01529</td>\n",
       "      <td>-0.03097</td>\n",
       "      <td>-0.00570</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7793</th>\n",
       "      <td>677.31958</td>\n",
       "      <td>102.53516</td>\n",
       "      <td>5.04336</td>\n",
       "      <td>-16.21258</td>\n",
       "      <td>91.28848</td>\n",
       "      <td>46.76449</td>\n",
       "      <td>-122.64320</td>\n",
       "      <td>10526.76953</td>\n",
       "      <td>27269.45117</td>\n",
       "      <td>3081.79126</td>\n",
       "      <td>-29477.96875</td>\n",
       "      <td>52.73388</td>\n",
       "      <td>2.15198</td>\n",
       "      <td>1.51168</td>\n",
       "      <td>0.01552</td>\n",
       "      <td>-0.02800</td>\n",
       "      <td>-0.00564</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7794</th>\n",
       "      <td>677.45129</td>\n",
       "      <td>102.48391</td>\n",
       "      <td>5.04739</td>\n",
       "      <td>-16.50119</td>\n",
       "      <td>90.87262</td>\n",
       "      <td>46.76449</td>\n",
       "      <td>-122.64310</td>\n",
       "      <td>10527.79102</td>\n",
       "      <td>27276.39258</td>\n",
       "      <td>3082.07373</td>\n",
       "      <td>-29477.79492</td>\n",
       "      <td>52.71768</td>\n",
       "      <td>2.13947</td>\n",
       "      <td>1.14636</td>\n",
       "      <td>0.01582</td>\n",
       "      <td>-0.02780</td>\n",
       "      <td>-0.00559</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7795 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      _totl,_time  Vtrue,_ktgs  pitch,__deg  _roll,__deg  hding,_true  \\\n",
       "0         5.48427    103.49908      0.07651     -0.00486    316.95850   \n",
       "1         5.60311    103.48605      0.33557     -0.02232    316.97202   \n",
       "2         5.71961    103.43369      0.62848     -0.03600    316.98975   \n",
       "3         5.80210    103.37489      0.83224     -0.04432    317.00247   \n",
       "4         5.89681    103.29092      1.05690     -0.05146    317.01611   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "7790    677.01807    102.64950      5.03510    -15.52756     92.21129   \n",
       "7791    677.11859    102.61120      5.03769    -15.75969     91.90834   \n",
       "7792    677.21912    102.57314      5.04044    -15.98804     91.60071   \n",
       "7793    677.31958    102.53516      5.04336    -16.21258     91.28848   \n",
       "7794    677.45129    102.48391      5.04739    -16.50119     90.87262   \n",
       "\n",
       "      __lat,__deg  __lon,__deg  ___CG,ftMSL  ____X,____m  ____Y,____m  \\\n",
       "0        46.56116   -122.69409   8150.02539  23464.83203   2437.26929   \n",
       "1        46.56120   -122.69415   8149.85596  23460.49609   2437.22852   \n",
       "2        46.56124   -122.69421   8149.62158  23456.24609   2437.16772   \n",
       "3        46.56127   -122.69424   8149.43262  23453.23828   2437.11768   \n",
       "4        46.56130   -122.69429   8149.20410  23449.78711   2437.05688   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "7790     46.76450   -122.64340  10524.41309  27253.54688   3081.13818   \n",
       "7791     46.76450   -122.64333  10525.20117  27258.84961   3081.35693   \n",
       "7792     46.76449   -122.64326  10525.98730  27264.15039   3081.57471   \n",
       "7793     46.76449   -122.64320  10526.76953  27269.45117   3081.79126   \n",
       "7794     46.76449   -122.64310  10527.79102  27276.39258   3082.07373   \n",
       "\n",
       "      ____Z,____m  ___vX,__m/s  ___vY,__m/s  ___vZ,__m/s  _elev,stick  \\\n",
       "0     -6846.28711    -36.49474     -0.21043    -38.77045     -0.04573   \n",
       "1     -6850.89453    -36.49013     -0.44140    -38.76478     -0.06844   \n",
       "2     -6855.40918    -36.47029     -0.57554    -38.74413     -0.05645   \n",
       "3     -6858.60400    -36.44852     -0.62677    -38.72172     -0.04408   \n",
       "4     -6862.26953    -36.41737     -0.65032    -38.68958     -0.03029   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "7790 -29478.54102     52.76324      2.18193      2.32113      0.01481   \n",
       "7791 -29478.32422     52.75458      2.17173      2.05556      0.01505   \n",
       "7792 -29478.13281     52.74484      2.16175      1.78573      0.01529   \n",
       "7793 -29477.96875     52.73388      2.15198      1.51168      0.01552   \n",
       "7794 -29477.79492     52.71768      2.13947      1.14636      0.01582   \n",
       "\n",
       "      ailrn,stick  ruddr,stick  thro1,engin  \n",
       "0         0.00032     -0.00179      0.62949  \n",
       "1        -0.00653     -0.00463      0.00000  \n",
       "2        -0.00832     -0.00633      0.00000  \n",
       "3        -0.00867     -0.00709      0.00000  \n",
       "4        -0.00876     -0.00772      0.00000  \n",
       "...           ...          ...          ...  \n",
       "7790     -0.03281     -0.00584      1.00000  \n",
       "7791     -0.03179     -0.00577      1.00000  \n",
       "7792     -0.03097     -0.00570      1.00000  \n",
       "7793     -0.02800     -0.00564      1.00000  \n",
       "7794     -0.02780     -0.00559      1.00000  \n",
       "\n",
       "[7795 rows x 18 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#relevent columes\n",
    "\n",
    "relevent_features = ['_totl,_time','Vtrue,_ktgs','pitch,__deg','_roll,__deg','hding,_true','__lat,__deg','__lon,__deg','___CG,ftMSL','____X,____m','____Y,____m','____Z,____m','___vX,__m/s','___vY,__m/s','___vZ,__m/s'\n",
    "                     ,'_elev,stick','ailrn,stick','ruddr,stick','thro1,engin'\n",
    "]\n",
    "\n",
    "train_data = pd.read_csv('data/Data4.csv')\n",
    "train_data = train_data.dropna(axis=1, how='all')\n",
    "train_data = train_data[relevent_features]\n",
    "train_data\n",
    "\n",
    "val_data = pd.read_csv('data/Data3.csv')\n",
    "val_data = val_data.dropna(axis=1, how='all')\n",
    "val_data = val_data[relevent_features]\n",
    "val_data\n",
    "\n",
    "test_data = pd.read_csv('data/Data2.csv')\n",
    "test_data = test_data.dropna(axis=1, how='all')\n",
    "test_data = test_data[relevent_features]\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATING A MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlightDataset(Dataset):\n",
    "    def __init__(self, df, seq_len, scaler=None):\n",
    "        # Keeping only the relevant features\n",
    "        relevant_features = ['_totl,_time', 'Vtrue,_ktgs', 'pitch,__deg', '_roll,__deg', 'hding,_true', '__lat,__deg', '__lon,__deg', '___CG,ftMSL', '____X,____m', '____Y,____m', '____Z,____m', '___vX,__m/s', '___vY,__m/s', '___vZ,__m/s', '_elev,stick', 'ailrn,stick', 'ruddr,stick', 'thro1,engin']\n",
    "        \n",
    "        self.df = df[relevant_features].copy()  # Use copy to avoid modifying the original DataFrame\n",
    "\n",
    "        # Changing the names of the features for easier use\n",
    "        self.df.columns = ['time', 'vt', 'pitch', 'roll', 'hding', 'lat', 'lon', 'alt', 'x', 'y', 'z', 'vx', 'vy', 'vz', 'elev_stick', 'ailrn_stick', 'ruddr_stick', 'throttle']\n",
    "        \n",
    "        if scaler is None:\n",
    "            self.scaler = StandardScaler()\n",
    "            self.df = pd.DataFrame(self.scaler.fit_transform(self.df), columns=self.df.columns)\n",
    "        else:\n",
    "            self.scaler = scaler\n",
    "            self.df = pd.DataFrame(self.scaler.transform(self.df), columns=self.df.columns)\n",
    "        \n",
    "        # Define sequence length\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        # Making the length shorter by seq_len so we always have a next_state\n",
    "        return len(self.df) - 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < self.seq_len:\n",
    "            padding = np.zeros((self.seq_len - idx, len(self.df.columns)))\n",
    "            current_state = np.vstack((padding, self.df.iloc[:idx].values.astype(float)))\n",
    "        else:\n",
    "            current_state = self.df.iloc[idx - self.seq_len:idx].values.astype(float)\n",
    "            \n",
    "        # Next state is the state at idx + seq_len\n",
    "        next_state = self.df.iloc[idx + 1][['lat', 'lon', 'alt', 'pitch', 'roll', 'hding', 'vx', 'vy', 'vz']].values.astype(float)\n",
    "\n",
    "        return torch.tensor(current_state, dtype=torch.float32), torch.tensor(next_state, dtype=torch.float32)\n",
    "    \n",
    "        # if idx < self.seq_len:\n",
    "        #     # Pad the sequence with zeros if idx is less than seq_len\n",
    "        #     padding = np.zeros((self.seq_len - idx, len(self.df.columns)))\n",
    "        #     current_state = np.vstack((padding, self.df.iloc[:idx + 1].values.astype(float)))\n",
    "        # else:\n",
    "        #     # Regular sequence extraction\n",
    "        #     current_state = self.df.iloc[idx - self.seq_len + 1:idx + 1].values.astype(float)\n",
    "        \n",
    "        # # Next state is the state at idx + 1\n",
    "        # next_state = self.df.iloc[idx + 1][['lat', 'lon', 'alt', 'pitch', 'roll', 'hding', 'vx', 'vy', 'vz']].values.astype(float)\n",
    "\n",
    "        # return torch.tensor(current_state, dtype=torch.float32), torch.tensor(next_state, dtype=torch.float32)\n",
    "    \n",
    "    def inverse_transform(self, data):\n",
    "        return self.scaler.inverse_transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlightLSTM(pl.LightningModule):\n",
    "    def __init__(self,input_dim,hidden_dim,num_layers,output_dim,lr=0.001):\n",
    "        super(FlightLSTM,self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim,hidden_dim,num_layers,batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.lr = lr\n",
    "        self.criterion = nn.MSELoss(reduction='none')\n",
    "\n",
    "        self.training_step_outputs = []\n",
    "        self.validation_step_outputs = []\n",
    "        self.test_step_outputs = []\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out,_ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "    def compute_metrics(self, y_true, y_pred):\n",
    "        mse = np.mean((y_true - y_pred) ** 2, axis=0)\n",
    "        mae = np.mean(np.abs(y_true - y_pred), axis=0)\n",
    "        return mse, mae\n",
    "        \n",
    "\n",
    "    def physics_loss(self, x, y, y_pred):\n",
    "        \"\"\"\n",
    "        Calculate the physics-based loss for the given predictions.\n",
    "\n",
    "        Args:\n",
    "        - x: Input tensor (shape: [batch_size, seq_len, num_features]).\n",
    "        - y: Target tensor (shape: [batch_size, num_output_features]).\n",
    "        - y_pred: Predicted tensor (shape: [batch_size, num_output_features]).\n",
    "\n",
    "        Returns:\n",
    "        - loss: Physics-based loss (scalar).\n",
    "        \"\"\"\n",
    "        m = 1127.177  # Total mass of the Cessna Skyhawk in kg\n",
    "\n",
    "        def compute_velocities(time):\n",
    "            out, _ = self.lstm(x)\n",
    "            out = self.fc(out[:, -1, :])\n",
    "            vx_pred = out[:, 6]\n",
    "            vy_pred = out[:, 7]\n",
    "            vz_pred = out[:, 8]\n",
    "            return vx_pred, vy_pred, vz_pred\n",
    "        \n",
    "        def compute_actual_velocities(time):\n",
    "            vx_actual = y[:, 6]\n",
    "            vy_actual = y[:, 7]\n",
    "            vz_actual = y[:, 8]\n",
    "            return vx_actual, vy_actual, vz_actual\n",
    "\n",
    "        # Extract the relevant features from y_pred\n",
    "        vx_pred = y_pred[:, 6]\n",
    "        vy_pred = y_pred[:, 7]\n",
    "        vz_pred = y_pred[:, 8]\n",
    "        pitch_pred = y_pred[:, 3]\n",
    "        roll_pred = y_pred[:, 4]\n",
    "        hding_pred = y_pred[:, 5]\n",
    "        # Extract time feature\n",
    "        time = x[:, :, 0]  # Assuming index 0 corresponds to 'time'\n",
    "        time.requires_grad_(True)\n",
    "        # Calculate derivatives with respect to time for the predicted velocities\n",
    "        vx_pred, vy_pred, vz_pred = compute_velocities(time)\n",
    "        jacobians = F.jacobian(compute_velocities, time, create_graph=True, strict=False, vectorize=True)\n",
    "        dvx_dt_pred, dvy_dt_pred, dvz_dt_pred = jacobians\n",
    "\n",
    "        vx_pred = vx_pred.unsqueeze(1).unsqueeze(2)  # Shape: [64, 1, 1]\n",
    "        vy_pred = vy_pred.unsqueeze(1).unsqueeze(2)  # Shape: [64, 1, 1]\n",
    "        vz_pred = vz_pred.unsqueeze(1).unsqueeze(2)  # Shape: [64, 1, 1]\n",
    "\n",
    "        pitch_pred = pitch_pred.unsqueeze(1).unsqueeze(2)  # Shape: [64, 1, 1]\n",
    "        roll_pred = roll_pred.unsqueeze(1).unsqueeze(2)    # Shape: [64, 1, 1]\n",
    "        hding_pred = hding_pred.unsqueeze(1).unsqueeze(2)  # Shape: [64, 1, 1]\n",
    "\n",
    "        \n",
    "        # Calculate predicted forces\n",
    "        X_pred = m * (dvx_dt_pred + pitch_pred * vz_pred - hding_pred * vy_pred)\n",
    "        Y_pred = m * (dvy_dt_pred + hding_pred * vx_pred - roll_pred * vz_pred)\n",
    "        Z_pred = m * (dvz_dt_pred + roll_pred * vy_pred - pitch_pred * vx_pred)\n",
    "\n",
    "        # Extract the relevant features from y\n",
    "        pitch_actual = y[:, 3]  # Index 3 corresponds to 'pitch'\n",
    "        roll_actual = y[:, 4]  # Index 4 corresponds to 'roll'\n",
    "        hding_actual = y[:, 5]  # Index 5 corresponds to 'hding'\n",
    "        vx_actual = y[:, 6]\n",
    "        vy_actual = y[:, 7]\n",
    "        vz_actual = y[:, 8]\n",
    "\n",
    "        # Calculate derivatives with respect to time for the actual velocities\n",
    "        vx_actual, vy_actual, vz_actual = compute_actual_velocities(time)\n",
    "        jacobians_actual = F.jacobian(compute_actual_velocities, time, create_graph=True, strict=False, vectorize=True)\n",
    "        dvx_dt_actual, dvy_dt_actual, dvz_dt_actual = jacobians_actual\n",
    "\n",
    "        vx_actual = vx_actual.unsqueeze(1).unsqueeze(2)  # Shape: [64, 1, 1]\n",
    "        vy_actual = vy_actual.unsqueeze(1).unsqueeze(2)  # Shape: [64, 1, 1]\n",
    "        vz_actual = vz_actual.unsqueeze(1).unsqueeze(2)  # Shape: [64, 1, 1]\n",
    "\n",
    "        pitch_actual = pitch_actual.unsqueeze(1).unsqueeze(2)  # Shape: [64, 1, 1]\n",
    "        roll_actual = roll_actual.unsqueeze(1).unsqueeze(2)    # Shape: [64, 1, 1]\n",
    "        hding_actual = hding_actual.unsqueeze(1).unsqueeze(2)  # Shape: [64, 1, 1]\n",
    "\n",
    "        # Calculate actual forces\n",
    "        X_actual = m * (dvx_dt_actual + pitch_actual * vz_actual - hding_actual * vy_actual)\n",
    "        Y_actual = m * (dvy_dt_actual + hding_actual * vx_actual - roll_actual * vz_actual)\n",
    "        Z_actual = m * (dvz_dt_actual + roll_actual * vy_actual - pitch_actual * vx_actual)\n",
    "\n",
    "        # Compute physics-based loss\n",
    "        loss_X = torch.mean((X_pred - X_actual) ** 2)\n",
    "        loss_Y = torch.mean((Y_pred - Y_actual) ** 2)\n",
    "        loss_Z = torch.mean((Z_pred - Z_actual) ** 2)\n",
    "\n",
    "        physics_loss = loss_X + loss_Y + loss_Z\n",
    "        return physics_loss\n",
    "\n",
    "        \n",
    "    \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        x, y = batch\n",
    "        output = self(x)\n",
    "        mse_loss = self.criterion(output, y).mean()\n",
    "        phys_loss = self.physics_loss(x, y, output)\n",
    "        loss = mse_loss + phys_loss\n",
    "        self.log(\"train/batch/loss\", loss, prog_bar=False)\n",
    "\n",
    "        y_true = y.cpu().detach().numpy()\n",
    "        y_pred = output.cpu().detach().numpy()\n",
    "\n",
    "        mse, mae = self.compute_metrics(y_true, y_pred)\n",
    "\n",
    "        for i, feature in enumerate(['lat', 'lon', 'alt', 'pitch', 'roll', 'hding', 'vx', 'vy', 'vz']):\n",
    "            self.log(f\"train/batch/mse_{feature}\", mse[i], prog_bar=False)\n",
    "            self.log(f\"train/batch/mae_{feature}\", mae[i], prog_bar=False)\n",
    "\n",
    "        self.training_step_outputs.append({\"loss\": loss, \"mse\": mse, \"mae\": mae, \"y_true\": y_true, \"y_pred\": y_pred})\n",
    "\n",
    "        return {\"loss\": loss, \"mse\": mse, \"mae\": mae}\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        loss = np.array([output[\"loss\"].detach().cpu().numpy() for output in self.training_step_outputs])\n",
    "        mse = np.vstack([output[\"mse\"] for output in self.training_step_outputs])\n",
    "        mae = np.vstack([output[\"mae\"] for output in self.training_step_outputs])\n",
    "\n",
    "        y_true_all = np.vstack([output[\"y_true\"] for output in self.training_step_outputs])\n",
    "        y_pred_all = np.vstack([output[\"y_pred\"] for output in self.training_step_outputs])\n",
    "\n",
    "        mse_all = np.mean(mse, axis=0)\n",
    "        mae_all = np.mean(mae, axis=0)\n",
    "        r2_all = r2_score(y_true_all, y_pred_all)\n",
    "\n",
    "        self.log(\"train/epoch/loss\", loss.mean())  # Log training epoch loss\n",
    "        for i, feature in enumerate(['lat', 'lon', 'alt', 'pitch', 'roll', 'hding', 'vx', 'vy', 'vz']):\n",
    "            self.log(f\"train/epoch/mse_{feature}\", mse_all[i])  # Log training epoch MSE for each feature\n",
    "            self.log(f\"train/epoch/mae_{feature}\", mae_all[i])  # Log training epoch MAE for each feature\n",
    "        self.log(\"train/epoch/r2\", r2_all)  # Log training epoch R²\n",
    "\n",
    "\n",
    "        print(\"Training Epoch End: Loss:\", loss.mean(), \"MSE:\", mse_all, \"MAE:\", mae_all, \"R²:\", r2_all)  # Debugging print\n",
    "        \n",
    "        self.training_step_outputs.clear()\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        output = self(x)\n",
    "        mse_loss = self.criterion(output, y).mean()\n",
    "        phys_loss = self.physics_loss(x, y, output)\n",
    "        loss = mse_loss + phys_loss\n",
    "\n",
    "        y_true = y.cpu().detach().numpy()\n",
    "        y_pred = output.cpu().detach().numpy()\n",
    "\n",
    "        mse, mae = self.compute_metrics(y_true, y_pred)\n",
    "\n",
    "        for i, feature in enumerate(['lat', 'lon', 'alt', 'pitch', 'roll', 'hding', 'vx', 'vy', 'vz']):\n",
    "            self.log(f\"val/batch/mse_{feature}\", mse[i], prog_bar=False)\n",
    "            self.log(f\"val/batch/mae_{feature}\", mae[i], prog_bar=False)\n",
    "\n",
    "        self.validation_step_outputs.append({\"loss\": loss, \"mse\": mse, \"mae\": mae, \"y_true\": y_true, \"y_pred\": y_pred})\n",
    "\n",
    "        return {\"loss\": loss, \"mse\": mse, \"mae\": mae}\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        loss = np.array([output[\"loss\"].detach().cpu().numpy() for output in self.validation_step_outputs])\n",
    "        mse = np.vstack([output[\"mse\"] for output in self.validation_step_outputs])\n",
    "        mae = np.vstack([output[\"mae\"] for output in self.validation_step_outputs])\n",
    "\n",
    "        y_true_all = np.vstack([output[\"y_true\"] for output in self.validation_step_outputs])\n",
    "        y_pred_all = np.vstack([output[\"y_pred\"] for output in self.validation_step_outputs])\n",
    "\n",
    "        mse_all = np.mean(mse, axis=0)\n",
    "        mae_all = np.mean(mae, axis=0)\n",
    "        r2_all = r2_score(y_true_all, y_pred_all)\n",
    "\n",
    "        self.log(\"val/epoch/loss\", loss.mean())  # Log validation epoch loss\n",
    "        for i, feature in enumerate(['lat', 'lon', 'alt', 'pitch', 'roll', 'hding', 'vx', 'vy', 'vz']):\n",
    "            self.log(f\"val/epoch/mse_{feature}\", mse_all[i])  # Log validation epoch MSE for each feature\n",
    "            self.log(f\"val/epoch/mae_{feature}\", mae_all[i])  # Log validation epoch MAE for each feature\n",
    "        self.log(\"val/epoch/r2\", r2_all)  # Log validation epoch R²\n",
    "\n",
    "        print(\"Validation Epoch End: Loss:\", loss.mean(), \"MSE:\", mse_all, \"MAE:\", mae_all, \"R²:\", r2_all)  # Debugging print\n",
    "\n",
    "        self.validation_step_outputs.clear()  # free memory\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        output = self(x)\n",
    "        loss = self.criterion(output, y).mean()\n",
    "\n",
    "        y_true = y.cpu().detach().numpy()\n",
    "        y_pred = output.cpu().detach().numpy()\n",
    "\n",
    "        mse, mae = self.compute_metrics(y_true, y_pred)\n",
    "\n",
    "        for i, feature in enumerate(['lat', 'lon', 'alt', 'pitch', 'roll', 'hding', 'vx', 'vy', 'vz']):\n",
    "            self.log(f\"test/batch/mse_{feature}\", mse[i], prog_bar=False)\n",
    "            self.log(f\"test/batch/mae_{feature}\", mae[i], prog_bar=False)\n",
    "\n",
    "        self.test_step_outputs.append({\"loss\": loss, \"mse\": mse, \"mae\": mae, \"y_true\": y_true, \"y_pred\": y_pred})\n",
    "\n",
    "        return {\"loss\": loss, \"mse\": mse, \"mae\": mae}\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        loss = np.array([output[\"loss\"].detach().cpu().numpy() for output in self.test_step_outputs])\n",
    "        mse = np.vstack([output[\"mse\"] for output in self.test_step_outputs])\n",
    "        mae = np.vstack([output[\"mae\"] for output in self.test_step_outputs])\n",
    "\n",
    "        y_true_all = np.vstack([output[\"y_true\"] for output in self.test_step_outputs])\n",
    "        y_pred_all = np.vstack([output[\"y_pred\"] for output in self.test_step_outputs])\n",
    "\n",
    "        mse_all = np.mean(mse, axis=0)\n",
    "        mae_all = np.mean(mae, axis=0)\n",
    "        r2_all = r2_score(y_true_all, y_pred_all)\n",
    "\n",
    "        self.log(\"test/epoch/loss\", loss.mean())  # Log test epoch loss\n",
    "        for i, feature in enumerate(['lat', 'lon', 'alt', 'pitch', 'roll', 'hding', 'vx', 'vy', 'vz']):\n",
    "            self.log(f\"test/epoch/mse_{feature}\", mse_all[i])  # Log test epoch MSE for each feature\n",
    "            self.log(f\"test/epoch/mae_{feature}\", mae_all[i])  # Log test epoch MAE for each feature\n",
    "        self.log(\"test/epoch/r2\", r2_all)  # Log test epoch R²\n",
    "\n",
    "        print(\"Test Epoch End: Loss:\", loss.mean(), \"MSE:\", mse_all, \"MAE:\", mae_all, \"R²:\", r2_all)  # Debugging print\n",
    "\n",
    "        self.test_step_outputs.clear()  # free memory\n",
    "\n",
    "    def save_predictions_to_csv(self, test_data):\n",
    "        predictions = []\n",
    "        actual_data = []\n",
    "        \n",
    "        for batch in test_data:\n",
    "            x, y = batch\n",
    "            output = self.forward(x)\n",
    "            predictions.append(output.cpu().detach().numpy())\n",
    "            actual_data.append(y.cpu().detach().numpy())\n",
    "            \n",
    "        predictions = np.vstack(predictions)\n",
    "        actual_data = np.vstack(actual_data)\n",
    "\n",
    "        # Use the scaler to inverse transform only the predictions and actuals, ensuring alignment with the scaler's feature order\n",
    "        num_samples = predictions.shape[0]\n",
    "        all_features = ['time', 'vt', 'pitch', 'roll', 'hding', 'lat', 'lon', 'alt', 'x', 'y', 'z', 'vx', 'vy', 'vz', 'elev_stick', 'ailrn_stick', 'ruddr_stick', 'throttle']\n",
    "        relevant_indices = [all_features.index(feature) for feature in ['lat', 'lon', 'alt', 'pitch', 'roll', 'hding', 'vx', 'vy', 'vz']]\n",
    "        \n",
    "        # Create a zero matrix with the same shape as the scaler's expected input\n",
    "        padded_predictions = np.zeros((num_samples, len(all_features)))\n",
    "        padded_actual_data = np.zeros((num_samples, len(all_features)))\n",
    "\n",
    "        # Place the predictions and actual data in the correct positions\n",
    "        padded_predictions[:, relevant_indices] = predictions\n",
    "        padded_actual_data[:, relevant_indices] = actual_data\n",
    "\n",
    "        # Inverse transform\n",
    "        scaler = test_data.dataset.scaler\n",
    "        unnormalized_predictions = scaler.inverse_transform(padded_predictions)[:, relevant_indices]\n",
    "        unnormalized_actual_data = scaler.inverse_transform(padded_actual_data)[:, relevant_indices]\n",
    "\n",
    "        # Create dataframes for the unnormalized predictions and actual values\n",
    "        columns = ['lat', 'lon', 'alt', 'pitch', 'roll', 'hding', 'vx', 'vy', 'vz']\n",
    "        predictions_df = pd.DataFrame(unnormalized_predictions, columns=[f'predicted_{col}' for col in columns])\n",
    "        actual_data_df = pd.DataFrame(unnormalized_actual_data, columns=[f'actual_{col}' for col in columns])\n",
    "        \n",
    "        # Combine the dataframes such that each predicted value is next to its corresponding actual value\n",
    "        combined_df = pd.DataFrame()\n",
    "        for col in columns:\n",
    "            combined_df[f'predicted_{col}'] = predictions_df[f'predicted_{col}']\n",
    "            combined_df[f'actual_{col}'] = actual_data_df[f'actual_{col}']\n",
    "        \n",
    "        combined_df.to_csv('test.csv', index=False)\n",
    "\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "def seed_everything(seed=42):\n",
    "    # random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    pl.seed_everything(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set the seed\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequance_length = 20\n",
    "train_dataset = FlightDataset(train_data, sequance_length)\n",
    "fitted_scaler = train_dataset.scaler\n",
    "val_dataset = FlightDataset(val_data, sequance_length, fitted_scaler)\n",
    "test_dataset = FlightDataset(test_data, sequance_length, fitted_scaler)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:  tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.7447e+02, 6.5175e+01, 1.0840e+01,  ..., 6.1500e-03,\n",
      "          1.8000e-02, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.7447e+02, 6.5175e+01, 1.0840e+01,  ..., 6.1500e-03,\n",
      "          1.8000e-02, 1.0000e+00],\n",
      "         [1.7457e+02, 6.5177e+01, 1.0829e+01,  ..., 6.2100e-03,\n",
      "          1.7780e-02, 1.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.7859e+02, 6.5510e+01, 1.0369e+01,  ..., 7.1500e-03,\n",
      "          9.4900e-03, 1.0000e+00],\n",
      "         [1.7869e+02, 6.5524e+01, 1.0359e+01,  ..., 7.1500e-03,\n",
      "          9.2900e-03, 1.0000e+00],\n",
      "         [1.7880e+02, 6.5537e+01, 1.0349e+01,  ..., 7.1500e-03,\n",
      "          9.1200e-03, 1.0000e+00],\n",
      "         ...,\n",
      "         [1.8030e+02, 6.5756e+01, 1.0218e+01,  ..., 7.0500e-03,\n",
      "          6.1000e-03, 1.0000e+00],\n",
      "         [1.8040e+02, 6.5772e+01, 1.0210e+01,  ..., 7.0400e-03,\n",
      "          5.9100e-03, 1.0000e+00],\n",
      "         [1.8050e+02, 6.5787e+01, 1.0203e+01,  ..., 6.8000e-03,\n",
      "          5.5300e-03, 1.0000e+00]],\n",
      "\n",
      "        [[1.7869e+02, 6.5524e+01, 1.0359e+01,  ..., 7.1500e-03,\n",
      "          9.2900e-03, 1.0000e+00],\n",
      "         [1.7880e+02, 6.5537e+01, 1.0349e+01,  ..., 7.1500e-03,\n",
      "          9.1200e-03, 1.0000e+00],\n",
      "         [1.7890e+02, 6.5551e+01, 1.0339e+01,  ..., 7.1600e-03,\n",
      "          8.9200e-03, 1.0000e+00],\n",
      "         ...,\n",
      "         [1.8040e+02, 6.5772e+01, 1.0210e+01,  ..., 7.0400e-03,\n",
      "          5.9100e-03, 1.0000e+00],\n",
      "         [1.8050e+02, 6.5787e+01, 1.0203e+01,  ..., 6.8000e-03,\n",
      "          5.5300e-03, 1.0000e+00],\n",
      "         [1.8055e+02, 6.5795e+01, 1.0200e+01,  ..., 6.4400e-03,\n",
      "          4.9800e-03, 1.0000e+00]],\n",
      "\n",
      "        [[1.7880e+02, 6.5537e+01, 1.0349e+01,  ..., 7.1500e-03,\n",
      "          9.1200e-03, 1.0000e+00],\n",
      "         [1.7890e+02, 6.5551e+01, 1.0339e+01,  ..., 7.1600e-03,\n",
      "          8.9200e-03, 1.0000e+00],\n",
      "         [1.7900e+02, 6.5565e+01, 1.0329e+01,  ..., 7.1500e-03,\n",
      "          8.7100e-03, 1.0000e+00],\n",
      "         ...,\n",
      "         [1.8050e+02, 6.5787e+01, 1.0203e+01,  ..., 6.8000e-03,\n",
      "          5.5300e-03, 1.0000e+00],\n",
      "         [1.8055e+02, 6.5795e+01, 1.0200e+01,  ..., 6.4400e-03,\n",
      "          4.9800e-03, 1.0000e+00],\n",
      "         [1.8060e+02, 6.5802e+01, 1.0196e+01,  ..., 6.1500e-03,\n",
      "          4.4600e-03, 1.0000e+00]]])\n",
      "Targets:  tensor([[  45.5864, -122.5741,  101.7368,   10.8295,   -0.3517,  299.2433,\n",
      "          -29.2273,    3.6507,  -16.4046],\n",
      "        [  45.5864, -122.5741,  102.8978,   10.8188,   -0.3565,  299.2404,\n",
      "          -29.2300,    3.6459,  -16.4023],\n",
      "        [  45.5864, -122.5742,  104.0571,   10.8080,   -0.3612,  299.2373,\n",
      "          -29.2328,    3.6409,  -16.4001],\n",
      "        [  45.5864, -122.5742,  105.2147,   10.7969,   -0.3656,  299.2341,\n",
      "          -29.2358,    3.6358,  -16.3979],\n",
      "        [  45.5865, -122.5742,  106.3707,   10.7857,   -0.3699,  299.2308,\n",
      "          -29.2390,    3.6305,  -16.3958],\n",
      "        [  45.5865, -122.5743,  107.5249,   10.7743,   -0.3740,  299.2274,\n",
      "          -29.2424,    3.6251,  -16.3937],\n",
      "        [  45.5865, -122.5743,  108.6772,   10.7627,   -0.3779,  299.2240,\n",
      "          -29.2459,    3.6196,  -16.3916],\n",
      "        [  45.5865, -122.5744,  109.8278,   10.7511,   -0.3816,  299.2204,\n",
      "          -29.2496,    3.6140,  -16.3896],\n",
      "        [  45.5865, -122.5744,  110.9764,   10.7393,   -0.3852,  299.2168,\n",
      "          -29.2536,    3.6083,  -16.3876],\n",
      "        [  45.5865, -122.5744,  112.1232,   10.7275,   -0.3887,  299.2131,\n",
      "          -29.2577,    3.6025,  -16.3857],\n",
      "        [  45.5865, -122.5745,  113.2680,   10.7155,   -0.3920,  299.2094,\n",
      "          -29.2619,    3.5967,  -16.3839],\n",
      "        [  45.5866, -122.5745,  114.4110,   10.7035,   -0.3951,  299.2056,\n",
      "          -29.2663,    3.5909,  -16.3821],\n",
      "        [  45.5866, -122.5745,  115.5519,   10.6915,   -0.3980,  299.2016,\n",
      "          -29.2708,    3.5849,  -16.3803],\n",
      "        [  45.5866, -122.5746,  116.6910,   10.6794,   -0.4008,  299.1976,\n",
      "          -29.2755,    3.5790,  -16.3786],\n",
      "        [  45.5866, -122.5746,  117.8280,   10.6672,   -0.4035,  299.1935,\n",
      "          -29.2803,    3.5730,  -16.3770],\n",
      "        [  45.5866, -122.5747,  118.9631,   10.6551,   -0.4060,  299.1894,\n",
      "          -29.2853,    3.5671,  -16.3754],\n",
      "        [  45.5866, -122.5747,  120.0962,   10.6429,   -0.4084,  299.1853,\n",
      "          -29.2905,    3.5611,  -16.3738],\n",
      "        [  45.5867, -122.5747,  121.2274,   10.6308,   -0.4108,  299.1812,\n",
      "          -29.2958,    3.5552,  -16.3724],\n",
      "        [  45.5867, -122.5748,  122.3566,   10.6186,   -0.4130,  299.1772,\n",
      "          -29.3013,    3.5493,  -16.3710],\n",
      "        [  45.5867, -122.5748,  123.4838,   10.6065,   -0.4152,  299.1732,\n",
      "          -29.3069,    3.5434,  -16.3696],\n",
      "        [  45.5867, -122.5749,  124.6092,   10.5944,   -0.4172,  299.1692,\n",
      "          -29.3127,    3.5376,  -16.3684],\n",
      "        [  45.5867, -122.5749,  125.7326,   10.5823,   -0.4192,  299.1653,\n",
      "          -29.3186,    3.5318,  -16.3672],\n",
      "        [  45.5867, -122.5749,  126.8541,   10.5703,   -0.4211,  299.1614,\n",
      "          -29.3247,    3.5261,  -16.3661],\n",
      "        [  45.5867, -122.5750,  127.9737,   10.5583,   -0.4229,  299.1575,\n",
      "          -29.3309,    3.5204,  -16.3650],\n",
      "        [  45.5868, -122.5750,  129.0914,   10.5464,   -0.4246,  299.1537,\n",
      "          -29.3372,    3.5148,  -16.3640],\n",
      "        [  45.5868, -122.5750,  130.2074,   10.5346,   -0.4263,  299.1500,\n",
      "          -29.3436,    3.5093,  -16.3630],\n",
      "        [  45.5868, -122.5751,  131.3215,   10.5228,   -0.4278,  299.1463,\n",
      "          -29.3501,    3.5038,  -16.3622],\n",
      "        [  45.5868, -122.5751,  132.4338,   10.5111,   -0.4291,  299.1425,\n",
      "          -29.3567,    3.4984,  -16.3613],\n",
      "        [  45.5868, -122.5751,  133.5443,   10.4995,   -0.4304,  299.1386,\n",
      "          -29.3635,    3.4931,  -16.3606],\n",
      "        [  45.5868, -122.5752,  134.6532,   10.4880,   -0.4315,  299.1347,\n",
      "          -29.3704,    3.4879,  -16.3599],\n",
      "        [  45.5868, -122.5752,  135.7603,   10.4766,   -0.4326,  299.1308,\n",
      "          -29.3774,    3.4828,  -16.3593],\n",
      "        [  45.5869, -122.5753,  136.8657,   10.4653,   -0.4335,  299.1270,\n",
      "          -29.3845,    3.4778,  -16.3588],\n",
      "        [  45.5869, -122.5753,  137.9695,   10.4541,   -0.4345,  299.1232,\n",
      "          -29.3918,    3.4729,  -16.3583],\n",
      "        [  45.5869, -122.5753,  139.0717,   10.4430,   -0.4354,  299.1195,\n",
      "          -29.3990,    3.4681,  -16.3578],\n",
      "        [  45.5869, -122.5754,  140.1723,   10.4320,   -0.4361,  299.1159,\n",
      "          -29.4064,    3.4634,  -16.3575],\n",
      "        [  45.5869, -122.5754,  141.2714,   10.4212,   -0.4368,  299.1122,\n",
      "          -29.4139,    3.4589,  -16.3572],\n",
      "        [  45.5869, -122.5754,  142.3690,   10.4104,   -0.4374,  299.1086,\n",
      "          -29.4214,    3.4544,  -16.3569],\n",
      "        [  45.5869, -122.5755,  143.4652,   10.3998,   -0.4378,  299.1049,\n",
      "          -29.4291,    3.4500,  -16.3568],\n",
      "        [  45.5870, -122.5755,  144.5599,   10.3893,   -0.4382,  299.1012,\n",
      "          -29.4368,    3.4458,  -16.3567],\n",
      "        [  45.5870, -122.5756,  145.6532,   10.3790,   -0.4385,  299.0975,\n",
      "          -29.4445,    3.4416,  -16.3566],\n",
      "        [  45.5870, -122.5756,  146.7451,   10.3688,   -0.4387,  299.0938,\n",
      "          -29.4524,    3.4376,  -16.3566],\n",
      "        [  45.5870, -122.5757,  147.8358,   10.3587,   -0.4388,  299.0902,\n",
      "          -29.4603,    3.4337,  -16.3566],\n",
      "        [  45.5870, -122.5757,  148.9252,   10.3488,   -0.4388,  299.0865,\n",
      "          -29.4682,    3.4299,  -16.3567],\n",
      "        [  45.5870, -122.5757,  150.0133,   10.3390,   -0.4387,  299.0829,\n",
      "          -29.4762,    3.4262,  -16.3569],\n",
      "        [  45.5871, -122.5758,  151.1003,   10.3293,   -0.4387,  299.0793,\n",
      "          -29.4843,    3.4226,  -16.3571],\n",
      "        [  45.5871, -122.5758,  152.1860,   10.3198,   -0.4386,  299.0759,\n",
      "          -29.4925,    3.4192,  -16.3574],\n",
      "        [  45.5871, -122.5758,  153.2707,   10.3105,   -0.4384,  299.0726,\n",
      "          -29.5006,    3.4159,  -16.3577],\n",
      "        [  45.5871, -122.5759,  154.3543,   10.3013,   -0.4382,  299.0693,\n",
      "          -29.5088,    3.4127,  -16.3581],\n",
      "        [  45.5871, -122.5759,  155.4368,   10.2922,   -0.4380,  299.0660,\n",
      "          -29.5171,    3.4096,  -16.3585],\n",
      "        [  45.5871, -122.5759,  156.5183,   10.2833,   -0.4377,  299.0629,\n",
      "          -29.5254,    3.4067,  -16.3590],\n",
      "        [  45.5871, -122.5760,  157.5989,   10.2746,   -0.4374,  299.0598,\n",
      "          -29.5338,    3.4038,  -16.3596],\n",
      "        [  45.5872, -122.5760,  158.6786,   10.2660,   -0.4370,  299.0568,\n",
      "          -29.5421,    3.4011,  -16.3602],\n",
      "        [  45.5872, -122.5761,  159.7574,   10.2576,   -0.4365,  299.0537,\n",
      "          -29.5505,    3.3986,  -16.3608],\n",
      "        [  45.5872, -122.5761,  160.8353,   10.2493,   -0.4360,  299.0507,\n",
      "          -29.5590,    3.3961,  -16.3615],\n",
      "        [  45.5872, -122.5761,  161.9125,   10.2412,   -0.4354,  299.0477,\n",
      "          -29.5674,    3.3938,  -16.3623],\n",
      "        [  45.5872, -122.5762,  162.9889,   10.2333,   -0.4347,  299.0447,\n",
      "          -29.5759,    3.3916,  -16.3631],\n",
      "        [  45.5872, -122.5762,  164.0646,   10.2255,   -0.4340,  299.0418,\n",
      "          -29.5844,    3.3895,  -16.3640],\n",
      "        [  45.5872, -122.5762,  165.1396,   10.2179,   -0.4333,  299.0389,\n",
      "          -29.5929,    3.3875,  -16.3648],\n",
      "        [  45.5873, -122.5763,  166.2140,   10.2104,   -0.4325,  299.0361,\n",
      "          -29.6014,    3.3857,  -16.3658],\n",
      "        [  45.5873, -122.5763,  167.2878,   10.2031,   -0.4317,  299.0335,\n",
      "          -29.6099,    3.3839,  -16.3666],\n",
      "        [  45.5873, -122.5763,  167.8245,   10.1995,   -0.4316,  299.0328,\n",
      "          -29.6142,    3.3831,  -16.3670],\n",
      "        [  45.5873, -122.5764,  168.3611,   10.1960,   -0.4317,  299.0326,\n",
      "          -29.6185,    3.3823,  -16.3674],\n",
      "        [  45.5873, -122.5764,  168.8975,   10.1925,   -0.4320,  299.0328,\n",
      "          -29.6227,    3.3816,  -16.3679],\n",
      "        [  45.5873, -122.5764,  169.4338,   10.1890,   -0.4324,  299.0334,\n",
      "          -29.6270,    3.3809,  -16.3683]])\n",
      "Size of inputs:  torch.Size([64, 20, 18])\n"
     ]
    }
   ],
   "source": [
    "# Assuming train_loader is your dataloader\n",
    "for batch in train_loader:\n",
    "    # Unpack the batch (assuming it contains inputs and targets)\n",
    "    inputs, targets = batch\n",
    "    \n",
    "    # Print the inputs and targets to understand their structure\n",
    "    print(\"Inputs: \", inputs)\n",
    "    print(\"Targets: \", targets)\n",
    "    \n",
    "    # Print the size of the inputs\n",
    "    print(\"Size of inputs: \", inputs.size())\n",
    "    \n",
    "    # Break the loop after the first batch\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "neptune_logger = NeptuneLogger(\n",
    "    api_key=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI4ZGJmNTQyNy04OWFhLTQ0YzMtYTA5Ni1hNTc1NjJmMGYxMjkifQ==\",\n",
    "    project=\"kapustya/example-project-tensorflow-keras\",\n",
    "    tags=[\"test\"],\n",
    "    log_model_checkpoints=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\milne\\PINN\\PINN-module-for-aircraft-simulator\\.conda\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:615: UserWarning: Checkpoint directory c:\\Users\\milne\\PINN\\PINN-module-for-aircraft-simulator\\.neptune\\None\\version_None\\checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "\n",
      "  | Name      | Type    | Params\n",
      "--------------------------------------\n",
      "0 | lstm      | LSTM    | 207 K \n",
      "1 | fc        | Linear  | 1.2 K \n",
      "2 | criterion | MSELoss | 0     \n",
      "--------------------------------------\n",
      "209 K     Trainable params\n",
      "0         Non-trainable params\n",
      "209 K     Total params\n",
      "0.836     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\milne\\PINN\\PINN-module-for-aircraft-simulator\\.conda\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 12.53it/s]Validation Epoch End: Loss: 102665975000000.0 MSE: [2.0807568e+03 1.4992217e+04 2.5379891e+04 1.0011569e+02 1.9454189e-01\n",
      " 8.9524281e+04 8.9094080e+02 1.0531891e+01 2.7429648e+02] MAE: [ 45.61531    122.4427     156.34145      9.985128     0.43931636\n",
      " 299.2061      29.84182      3.1796472   16.559624  ] R²: -2317987520.000504\n",
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\milne\\PINN\\PINN-module-for-aircraft-simulator\\.conda\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|████▉     | 50/101 [00:09<00:09,  5.46it/s][neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/kapustya/example-project-tensorflow-keras/e/TFKERAS-36\n",
      "Epoch 0: 100%|██████████| 101/101 [00:22<00:00,  4.59it/s, v_num=S-36]Validation Epoch End: Loss: 125225590000000.0 MSE: [1.0797274e+03 1.1848360e+04 4.4571465e+06 1.3480666e+02 2.6027536e+02\n",
      " 6.9944328e+04 1.6407393e+03 1.6880934e+02 1.2573130e+03] MAE: [  32.859188  108.850136 1947.6349     10.262973   11.410726  257.42047\n",
      "   37.042328   12.47407    32.69245 ] R²: -963612.972725955\n",
      "Epoch 0: 100%|██████████| 101/101 [00:31<00:00,  3.16it/s, v_num=S-36]Training Epoch End: Loss: 80194060000000.0 MSE: [1.5997089e+03 1.3478849e+04 1.0031814e+07 1.6555171e+02 3.9977475e+02\n",
      " 3.8525766e+04 9.8481079e+02 1.1059617e+02 1.4522279e+03] MAE: [  39.79744   116.02123  2865.3933     12.320004    9.823944  147.89116\n",
      "   26.772295    9.60571    34.865734] R²: -1773309.1100943768\n",
      "Epoch 1: 100%|██████████| 101/101 [00:18<00:00,  5.44it/s, v_num=S-36]Validation Epoch End: Loss: 118561550000000.0 MSE: [4.7095215e+02 9.1775146e+03 4.4078625e+06 1.7782637e+02 4.7522922e+02\n",
      " 7.4381812e+04 2.1889639e+03 2.1730101e+02 1.3095129e+03] MAE: [  21.70143    95.799324 1934.9435     12.20581    18.577412  265.90018\n",
      "   41.588894   14.258917   34.8514  ] R²: -589740.008730176\n",
      "Epoch 1: 100%|██████████| 101/101 [00:30<00:00,  3.30it/s, v_num=S-36]Training Epoch End: Loss: 78119880000000.0 MSE: [7.4250116e+02 1.0452510e+04 9.9554690e+06 2.7476279e+02 5.2872375e+02\n",
      " 4.1048766e+04 1.1448798e+03 2.4119331e+02 2.1453032e+03] MAE: [  27.064768  102.16789  2851.4478     16.041813   16.157017  156.38638\n",
      "   25.744396   15.183753   43.53228 ] R²: -1348831.5576615795\n",
      "Epoch 2: 100%|██████████| 101/101 [00:19<00:00,  5.13it/s, v_num=S-36]Validation Epoch End: Loss: 109028290000000.0 MSE: [1.7674284e+02 7.0353916e+03 4.3599695e+06 1.6749353e+02 7.9533820e+02\n",
      " 7.8507328e+04 2.8135913e+03 1.6870148e+02 1.4848458e+03] MAE: [  13.294452   83.87722  1922.5281     11.77476    25.409584  273.5479\n",
      "   46.772774   12.470373   36.88086 ] R²: -373077.75112838997\n",
      "Epoch 2: 100%|██████████| 101/101 [00:30<00:00,  3.29it/s, v_num=S-36]Training Epoch End: Loss: 74038750000000.0 MSE: [3.0634778e+02 8.0676992e+03 9.8845810e+06 3.0055069e+02 7.9926324e+02\n",
      " 4.3734391e+04 1.4563873e+03 2.4332263e+02 2.9530535e+03] MAE: [  17.338276   89.753555 2838.9546     16.780529   23.21016   164.70993\n",
      "   26.538837   15.284389   52.072605] R²: -1026994.5248411683\n",
      "Epoch 3: 100%|██████████| 101/101 [00:15<00:00,  6.57it/s, v_num=S-36]Validation Epoch End: Loss: 99883520000000.0 MSE: [5.7327839e+01 5.3237939e+03 4.3138300e+06 1.4545294e+02 1.1278951e+03\n",
      " 8.1818578e+04 3.3833889e+03 1.1756408e+02 1.7067688e+03] MAE: [   7.5714965   72.9643    1910.4905      10.784763    30.93038\n",
      "  279.53473     51.508133    10.175249    38.566708 ] R²: -249550.80297308209\n",
      "Epoch 3: 100%|██████████| 101/101 [00:25<00:00,  4.03it/s, v_num=S-36]Training Epoch End: Loss: 69746347000000.0 MSE: [1.0898734e+02 6.1455986e+03 9.8158000e+06 2.7229822e+02 1.1283903e+03\n",
      " 4.6096551e+04 1.8300780e+03 1.7997223e+02 3.7140586e+03] MAE: [  10.315108   78.329926 2826.7546     15.948609   29.370667  171.54123\n",
      "   30.917788   13.100675   59.035267] R²: -775747.9245133721\n",
      "Epoch 4: 100%|██████████| 101/101 [00:17<00:00,  5.74it/s, v_num=S-36]Validation Epoch End: Loss: 92886990000000.0 MSE: [1.5579090e+01 3.9645173e+03 4.2684740e+06 1.2833061e+02 1.4091042e+03\n",
      " 8.4221492e+04 3.8313201e+03 8.9348900e+01 1.9087012e+03] MAE: [   3.947      62.964382 1898.5835      9.933641   35.04312   283.80023\n",
      "   55.596558    8.583214   39.82833 ] R²: -174211.5003776706\n",
      "Epoch 4: 100%|██████████| 101/101 [00:27<00:00,  3.71it/s, v_num=S-36]Training Epoch End: Loss: 66546223000000.0 MSE: [3.3223476e+01 4.6154844e+03 9.7483690e+06 2.3859273e+02 1.4322736e+03\n",
      " 4.7921500e+04 2.1703149e+03 1.3100739e+02 4.3303545e+03] MAE: [   5.6763535   67.875336  2814.7832      14.901076    34.162464\n",
      "  176.57828     35.420345    11.067567    64.14143  ] R²: -580040.2753246246\n",
      "Epoch 5: 100%|██████████| 101/101 [00:15<00:00,  6.35it/s, v_num=S-36]Validation Epoch End: Loss: 88093690000000.0 MSE: [3.4761956e+00 2.8981907e+03 4.2237295e+06 1.1818261e+02 1.6204084e+03\n",
      " 8.5866289e+04 4.1545444e+03 7.6097229e+01 2.0658340e+03] MAE: [1.8643804e+00 5.3834816e+01 1.8867625e+03 9.3926592e+00 3.7893623e+01\n",
      " 2.8668347e+02 5.8376942e+01 7.6822767e+00 4.0713570e+01] R²: -123962.39248985349\n",
      "Epoch 5: 100%|██████████| 101/101 [00:25<00:00,  3.89it/s, v_num=S-36]Training Epoch End: Loss: 64582303000000.0 MSE: [8.5067492e+00 3.4068982e+03 9.6817950e+06 2.1445731e+02 1.6704774e+03\n",
      " 4.9212691e+04 2.4348621e+03 1.0500207e+02 4.7794570e+03] MAE: [   2.8633356   58.308388  2802.921       14.100386    37.563843\n",
      "  180.0287      38.62173      9.772803    67.62237  ] R²: -427313.1862638907\n",
      "Epoch 6: 100%|██████████| 101/101 [00:21<00:00,  4.68it/s, v_num=S-36]Validation Epoch End: Loss: 84950690000000.0 MSE: [6.14869237e-01 2.07556470e+03 4.17950575e+06 1.12667496e+02\n",
      " 1.76985376e+03 8.69613359e+04 4.37773438e+03 6.98567581e+01\n",
      " 2.17878296e+03] MAE: [7.8395569e-01 4.5558334e+01 1.8750062e+03 9.0840015e+00 3.9789268e+01\n",
      " 2.8858691e+02 6.0224873e+01 7.2075253e+00 4.1312931e+01] R²: -87973.94463372225\n",
      "Epoch 6: 100%|██████████| 101/101 [00:34<00:00,  2.92it/s, v_num=S-36]Training Epoch End: Loss: 63472218000000.0 MSE: [1.8096895e+00 2.4661628e+03 9.6159070e+06 1.9976259e+02 1.8408385e+03\n",
      " 5.0079871e+04 2.6232393e+03 9.2287514e+01 5.0870664e+03] MAE: [1.3188770e+00 4.9602196e+01 2.7911335e+03 1.3587551e+01 3.9805630e+01\n",
      " 1.8229649e+02 4.0771755e+01 9.0484362e+00 6.9906090e+01] R²: -309096.11667432927\n",
      "Epoch 7: 100%|██████████| 101/101 [00:19<00:00,  5.28it/s, v_num=S-36]Validation Epoch End: Loss: 82904655000000.0 MSE: [7.7794746e-02 1.4533673e+03 4.1357535e+06 1.0975414e+02 1.8730031e+03\n",
      " 8.7685703e+04 4.5293823e+03 6.6749397e+01 2.2571599e+03] MAE: [2.7840993e-01 3.8123016e+01 1.8633030e+03 8.9160442e+00 4.1048832e+01\n",
      " 2.8983917e+02 6.1450050e+01 6.9554219e+00 4.1735592e+01] R²: -61451.66731864112\n",
      "Epoch 7: 100%|██████████| 101/101 [00:34<00:00,  2.92it/s, v_num=S-36]Training Epoch End: Loss: 62849502000000.0 MSE: [3.1598821e-01 1.7471729e+03 9.5506140e+06 1.9118141e+02 1.9573762e+03\n",
      " 5.0648691e+04 2.7517153e+03 8.5899063e+01 5.2915371e+03] MAE: [5.5334169e-01 4.1743233e+01 2.7794048e+03 1.3278297e+01 4.1264687e+01\n",
      " 1.8376276e+02 4.2194069e+01 8.6522312e+00 7.1382675e+01] R²: -218935.02706414327\n",
      "Epoch 8: 100%|██████████| 101/101 [00:19<00:00,  5.15it/s, v_num=S-36]Validation Epoch End: Loss: 81558630000000.0 MSE: [4.4983579e-03 9.9312939e+02 4.0924420e+06 1.0824321e+02 1.9439795e+03\n",
      " 8.8167703e+04 4.6325107e+03 6.5101402e+01 2.3109841e+03] MAE: [6.4926848e-02 3.1513908e+01 1.8516624e+03 8.8275337e+00 4.1894737e+01\n",
      " 2.9066956e+02 6.2270210e+01 6.8164897e+00 4.2041000e+01] R²: -41972.20705841406\n",
      "Epoch 8: 100%|██████████| 101/101 [00:31<00:00,  3.17it/s, v_num=S-36]Training Epoch End: Loss: 62487404000000.0 MSE: [4.4775996e-02 1.2090643e+03 9.4858610e+06 1.8614597e+02 2.0358684e+03\n",
      " 5.1020016e+04 2.8379941e+03 8.2482269e+01 5.4262251e+03] MAE: [2.1091864e-01 3.4718346e+01 2.7677249e+03 1.3093461e+01 4.2217068e+01\n",
      " 1.8471030e+02 4.3137493e+01 8.4291162e+00 7.2337990e+01] R²: -151500.21871516434\n",
      "Epoch 9: 100%|██████████| 101/101 [00:15<00:00,  6.59it/s, v_num=S-36]Validation Epoch End: Loss: 80657000000000.0 MSE: [5.5465265e-04 6.6100024e+02 4.0495478e+06 1.0748795e+02 1.9932507e+03\n",
      " 8.8492289e+04 4.7033521e+03 6.4178535e+01 2.3480474e+03] MAE: [1.8123521e-02 2.5709883e+01 1.8401129e+03 8.7829351e+00 4.2472828e+01\n",
      " 2.9122739e+02 6.2827770e+01 6.7368984e+00 4.2252476e+01] R²: -27935.97588472808\n",
      "Epoch 9: 100%|██████████| 101/101 [00:25<00:00,  3.91it/s, v_num=S-36]Training Epoch End: Loss: 62264724000000.0 MSE: [5.9867678e-03 8.1566937e+02 9.4216130e+06 1.8312604e+02 2.0887903e+03\n",
      " 5.1263660e+04 2.8959556e+03 8.0529358e+01 5.5151812e+03] MAE: [7.2819784e-02 2.8509800e+01 2.7561021e+03 1.2981552e+01 4.2846550e+01\n",
      " 1.8532706e+02 4.3762047e+01 8.2974958e+00 7.2961487e+01] R²: -102208.31429220112\n",
      "Epoch 10: 100%|██████████| 101/101 [00:18<00:00,  5.46it/s, v_num=S-36]Validation Epoch End: Loss: 80040230000000.0 MSE: [2.28269678e-03 4.27699615e+02 4.00705075e+06 1.07144005e+02\n",
      " 2.02799426e+03 8.87141094e+04 4.75277588e+03 6.36401634e+01\n",
      " 2.37382153e+03] MAE: [4.4714645e-02 2.0680840e+01 1.8286432e+03 8.7625427e+00 4.2876095e+01\n",
      " 2.9160797e+02 6.3214085e+01 6.6898174e+00 4.2399899e+01] R²: -18078.345061888922\n",
      "Epoch 10: 100%|██████████| 101/101 [00:28<00:00,  3.60it/s, v_num=S-36]Training Epoch End: Loss: 62119265000000.0 MSE: [2.1933487e-03 5.3540344e+02 9.3578340e+06 1.8126767e+02 2.1248435e+03\n",
      " 5.1425145e+04 2.9352429e+03 7.9345673e+01 5.5744360e+03] MAE: [3.9035905e-02 2.3092197e+01 2.7445535e+03 1.2912467e+01 4.3269855e+01\n",
      " 1.8573270e+02 4.4179684e+01 8.2160454e+00 7.3373489e+01] R²: -67091.9797094515\n",
      "Epoch 11: 100%|██████████| 101/101 [00:18<00:00,  5.40it/s, v_num=S-36]Validation Epoch End: Loss: 79608890000000.0 MSE: [3.1996202e-03 2.6853528e+02 3.9649402e+06 1.0702536e+02 2.0529841e+03\n",
      " 8.8868102e+04 4.7879028e+03 6.3317219e+01 2.3919939e+03] MAE: [5.4012820e-02 1.6386965e+01 1.8172747e+03 8.7554941e+00 4.3164005e+01\n",
      " 2.9187195e+02 6.3487305e+01 6.6613445e+00 4.2503914e+01] R²: -11353.100672705994\n",
      "Epoch 11: 100%|██████████| 101/101 [00:30<00:00,  3.36it/s, v_num=S-36]Training Epoch End: Loss: 62018854000000.0 MSE: [2.1995641e-03 3.4126999e+02 9.2945070e+06 1.8009584e+02 2.1498010e+03\n",
      " 5.1533391e+04 2.9622439e+03 7.8592621e+01 5.6143594e+03] MAE: [4.1386981e-02 1.8430799e+01 2.7330742e+03 1.2868977e+01 4.3560398e+01\n",
      " 1.8600266e+02 4.4463661e+01 8.1634789e+00 7.3649513e+01] R²: -42767.454935425136\n",
      "Epoch 12: 100%|██████████| 101/101 [00:18<00:00,  5.49it/s, v_num=S-36]Validation Epoch End: Loss: 79300910000000.0 MSE: [3.54008772e-03 1.63324554e+02 3.92320525e+06 1.07029686e+02\n",
      " 2.07133740e+03 8.89765625e+04 4.81333838e+03 6.31203575e+01\n",
      " 2.40498779e+03] MAE: [5.7076916e-02 1.2779746e+01 1.8060131e+03 8.7557535e+00 4.3374306e+01\n",
      " 2.9205762e+02 6.3684475e+01 6.6438966e+00 4.2578308e+01] R²: -6907.5086657184465\n",
      "Epoch 12: 100%|██████████| 101/101 [00:30<00:00,  3.30it/s, v_num=S-36]Training Epoch End: Loss: 61946120000000.0 MSE: [2.3403966e-03 2.1082954e+02 9.2316190e+06 1.7934084e+02 2.1674104e+03\n",
      " 5.1606809e+04 2.9811018e+03 7.8094223e+01 5.6415811e+03] MAE: [4.2891890e-02 1.4481449e+01 2.7216643e+03 1.2841086e+01 4.3764217e+01\n",
      " 1.8618405e+02 4.4660282e+01 8.1283245e+00 7.3836937e+01] R²: -26423.215565272094\n",
      "Epoch 13: 100%|██████████| 101/101 [00:16<00:00,  6.18it/s, v_num=S-36]Validation Epoch End: Loss: 79076195000000.0 MSE: [3.7026892e-03 9.6061310e+01 3.8818362e+06 1.0709992e+02 2.0851372e+03\n",
      " 8.9054078e+04 4.8321445e+03 6.3000050e+01 2.4144270e+03] MAE: [5.8486424e-02 9.8009520e+00 1.7948274e+03 8.7599287e+00 4.3531796e+01\n",
      " 2.9219031e+02 6.3829922e+01 6.6332045e+00 4.2632427e+01] R²: -4065.3530081495865\n",
      "Epoch 13: 100%|██████████| 101/101 [00:26<00:00,  3.77it/s, v_num=S-36]Training Epoch End: Loss: 61891390000000.0 MSE: [2.4014905e-03 1.2599331e+02 9.1691530e+06 1.7884630e+02 2.1801101e+03\n",
      " 5.1657051e+04 2.9945127e+03 7.7753693e+01 5.6603657e+03] MAE: [4.3471560e-02 1.1190479e+01 2.7103203e+03 1.2822959e+01 4.3910610e+01\n",
      " 1.8630699e+02 4.4799110e+01 8.1040897e+00 7.3965897e+01] R²: -15792.982334149112\n",
      "Epoch 14: 100%|██████████| 101/101 [00:17<00:00,  5.82it/s, v_num=S-36]Validation Epoch End: Loss: 78908890000000.0 MSE: [3.8199620e-03 5.4556080e+01 3.8408282e+06 1.0720335e+02 2.0957573e+03\n",
      " 8.9110141e+04 4.8463320e+03 6.2927303e+01 2.4213889e+03] MAE: [5.9480004e-02 7.3860297e+00 1.7837118e+03 8.7660694e+00 4.3652687e+01\n",
      " 2.9228613e+02 6.3939468e+01 6.6267300e+00 4.2672333e+01] R²: -2311.6116220620497\n",
      "Epoch 14: 100%|██████████| 101/101 [00:28<00:00,  3.56it/s, v_num=S-36]Training Epoch End: Loss: 61848926000000.0 MSE: [2.4303414e-03 7.2696716e+01 9.1070990e+06 1.7851836e+02 2.1894934e+03\n",
      " 5.1691762e+04 3.0042361e+03 7.7514755e+01 5.6734854e+03] MAE: [4.3758765e-02 8.4963932e+00 2.6990425e+03 1.2811069e+01 4.4018471e+01\n",
      " 1.8639090e+02 4.4899040e+01 8.0869484e+00 7.4055725e+01] R²: -9114.611045176858\n",
      "Epoch 15: 100%|██████████| 101/101 [00:17<00:00,  5.87it/s, v_num=S-36]Validation Epoch End: Loss: 78781790000000.0 MSE: [3.9524133e-03 2.9877279e+01 3.8001702e+06 1.0732276e+02 2.1041282e+03\n",
      " 8.9151172e+04 4.8572632e+03 6.2886040e+01 2.4266028e+03] MAE: [6.0582638e-02 5.4657698e+00 1.7726685e+03 8.7731495e+00 4.3747711e+01\n",
      " 2.9235638e+02 6.4023735e+01 6.6230483e+00 4.2702229e+01] R²: -1268.8890681826676\n",
      "Epoch 15: 100%|██████████| 101/101 [00:28<00:00,  3.60it/s, v_num=S-36]Training Epoch End: Loss: 61815443000000.0 MSE: [2.4671054e-03 4.0426254e+01 9.0454510e+06 1.7829921e+02 2.1965852e+03\n",
      " 5.1715746e+04 3.0114128e+03 7.7343292e+01 5.6827202e+03] MAE: [4.4078179e-02 6.3326216e+00 2.6878416e+03 1.2803241e+01 4.4099899e+01\n",
      " 1.8644801e+02 4.4972374e+01 8.0745525e+00 7.4118874e+01] R²: -5070.847235110082\n",
      "Epoch 16: 100%|██████████| 101/101 [00:17<00:00,  5.76it/s, v_num=S-36]Validation Epoch End: Loss: 78801636000000.0 MSE: [4.3339981e-04 1.7458632e+01 3.7610718e+06 1.0779352e+02 2.1047104e+03\n",
      " 8.9128500e+04 4.8577886e+03 6.3048519e+01 2.4246824e+03] MAE: [1.5365615e-02 4.1780176e+00 1.7620465e+03 8.8010530e+00 4.3754360e+01\n",
      " 2.9231766e+02 6.4027779e+01 6.6375260e+00 4.2691326e+01] R²: -742.675513384555\n",
      "Epoch 16: 100%|██████████| 101/101 [00:27<00:00,  3.71it/s, v_num=S-36]Training Epoch End: Loss: 61859458000000.0 MSE: [7.1138074e-03 2.2069195e+01 8.9847960e+06 1.7813672e+02 2.2005352e+03\n",
      " 5.1719520e+04 3.0145845e+03 7.7217331e+01 5.6857290e+03] MAE: [5.9130099e-02 4.6810532e+00 2.6767905e+03 1.2798227e+01 4.4147186e+01\n",
      " 1.8646570e+02 4.5013233e+01 8.0658779e+00 7.4143723e+01] R²: -2770.4833941261686\n",
      "Epoch 17: 100%|██████████| 101/101 [00:15<00:00,  6.59it/s, v_num=S-36]Validation Epoch End: Loss: 78618640000000.0 MSE: [4.9239779e-03 7.9197640e+00 3.7199100e+06 1.0773037e+02 2.1155974e+03\n",
      " 8.9199984e+04 4.8714307e+03 6.2974953e+01 2.4330571e+03] MAE: [6.8132035e-02 2.8137393e+00 1.7508818e+03 8.7972803e+00 4.3877644e+01\n",
      " 2.9243994e+02 6.4132820e+01 6.6309724e+00 4.2739243e+01] R²: -341.54074691673156\n",
      "Epoch 17: 100%|██████████| 101/101 [00:24<00:00,  4.07it/s, v_num=S-36]Training Epoch End: Loss: 61776800000000.0 MSE: [2.8304723e-03 1.1095123e+01 8.9233520e+06 1.7849658e+02 2.2053040e+03\n",
      " 5.1737551e+04 3.0195239e+03 7.7392891e+01 5.6921094e+03] MAE: [4.6331249e-02 3.3103771e+00 2.6656721e+03 1.2811699e+01 4.4199551e+01\n",
      " 1.8650023e+02 4.5055370e+01 8.0775127e+00 7.4181992e+01] R²: -1395.3127450137524\n",
      "Epoch 18: 100%|██████████| 101/101 [00:16<00:00,  6.22it/s, v_num=S-36]Validation Epoch End: Loss: 78553050000000.0 MSE: [4.4017918e-03 3.8772819e+00 3.6802752e+06 1.0775243e+02 2.1205093e+03\n",
      " 8.9218016e+04 4.8773701e+03 6.2896500e+01 2.4355920e+03] MAE: [6.4185075e-02 1.9684118e+00 1.7401288e+03 8.7985802e+00 4.3933163e+01\n",
      " 2.9247073e+02 6.4178459e+01 6.6239843e+00 4.2753799e+01] R²: -170.52442124442592\n",
      "Epoch 18: 100%|██████████| 101/101 [00:26<00:00,  3.81it/s, v_num=S-36]Training Epoch End: Loss: 61747075000000.0 MSE: [2.6492407e-03 5.3981724e+00 8.8628520e+06 1.7820860e+02 2.2095037e+03\n",
      " 5.1750031e+04 3.0235471e+03 7.7172302e+01 5.6965078e+03] MAE: [4.5602094e-02 2.3087919e+00 2.6547012e+03 1.2801028e+01 4.4247643e+01\n",
      " 1.8652539e+02 4.5094540e+01 8.0617752e+00 7.4212799e+01] R²: -681.3553421694237\n",
      "Epoch 19: 100%|██████████| 101/101 [00:17<00:00,  5.77it/s, v_num=S-36]Validation Epoch End: Loss: 78500060000000.0 MSE: [4.4938810e-03 1.8326192e+00 3.6409742e+06 1.0781676e+02 2.1246877e+03\n",
      " 8.9231289e+04 4.8822480e+03 6.2867935e+01 2.4375696e+03] MAE: [6.4898647e-02 1.3527678e+00 1.7294513e+03 8.8023806e+00 4.3980347e+01\n",
      " 2.9249335e+02 6.4215935e+01 6.6214366e+00 4.2765152e+01] R²: -84.1821916910794\n",
      "Epoch 19: 100%|██████████| 101/101 [00:27<00:00,  3.73it/s, v_num=S-36]Training Epoch End: Loss: 61731045000000.0 MSE: [2.5369474e-03 2.5396097e+00 8.8027330e+06 1.7805659e+02 2.2127551e+03\n",
      " 5.1756090e+04 3.0264004e+03 7.7048004e+01 5.6992803e+03] MAE: [4.4796504e-02 1.5817420e+00 2.6438203e+03 1.2795528e+01 4.4284760e+01\n",
      " 1.8653824e+02 4.5123180e+01 8.0528193e+00 7.4231621e+01] R²: -323.10738828005555\n",
      "Epoch 20:  32%|███▏      | 32/101 [00:05<00:10,  6.39it/s, v_num=S-36] "
     ]
    }
   ],
   "source": [
    "seed_everything()\n",
    "torch.set_grad_enabled(True)\n",
    "input_dim = len(train_data.columns)\n",
    "hidden_dim = 128\n",
    "num_layers = 2\n",
    "output_dim = 9\n",
    "model = FlightLSTM(input_dim, hidden_dim, num_layers, output_dim)\n",
    "trainer = pl.Trainer(\n",
    "    logger = neptune_logger,\n",
    "    max_epochs=30\n",
    "    )\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "trainer.test(model, test_loader)\n",
    "model.save_predictions_to_csv(test_loader)\n",
    "neptune_logger.experiment.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PinnProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
