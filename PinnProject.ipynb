{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import lightning as L\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import BatchSizeFinder, LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import NeptuneLogger\n",
    "import neptune\n",
    "import os\n",
    "import torch.autograd.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and PreProcessing the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_totl,_time</th>\n",
       "      <th>Vtrue,_ktgs</th>\n",
       "      <th>pitch,__deg</th>\n",
       "      <th>_roll,__deg</th>\n",
       "      <th>hding,_true</th>\n",
       "      <th>__lat,__deg</th>\n",
       "      <th>__lon,__deg</th>\n",
       "      <th>___CG,ftMSL</th>\n",
       "      <th>____X,____m</th>\n",
       "      <th>____Y,____m</th>\n",
       "      <th>____Z,____m</th>\n",
       "      <th>___vX,__m/s</th>\n",
       "      <th>___vY,__m/s</th>\n",
       "      <th>___vZ,__m/s</th>\n",
       "      <th>_elev,stick</th>\n",
       "      <th>ailrn,stick</th>\n",
       "      <th>ruddr,stick</th>\n",
       "      <th>thro1,engin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.48427</td>\n",
       "      <td>103.49908</td>\n",
       "      <td>0.07651</td>\n",
       "      <td>-0.00486</td>\n",
       "      <td>316.95850</td>\n",
       "      <td>46.56116</td>\n",
       "      <td>-122.69409</td>\n",
       "      <td>8150.02539</td>\n",
       "      <td>23464.83203</td>\n",
       "      <td>2437.26929</td>\n",
       "      <td>-6846.28711</td>\n",
       "      <td>-36.49474</td>\n",
       "      <td>-0.21043</td>\n",
       "      <td>-38.77045</td>\n",
       "      <td>-0.04573</td>\n",
       "      <td>0.00032</td>\n",
       "      <td>-0.00179</td>\n",
       "      <td>0.62949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.60311</td>\n",
       "      <td>103.48605</td>\n",
       "      <td>0.33557</td>\n",
       "      <td>-0.02232</td>\n",
       "      <td>316.97202</td>\n",
       "      <td>46.56120</td>\n",
       "      <td>-122.69415</td>\n",
       "      <td>8149.85596</td>\n",
       "      <td>23460.49609</td>\n",
       "      <td>2437.22852</td>\n",
       "      <td>-6850.89453</td>\n",
       "      <td>-36.49013</td>\n",
       "      <td>-0.44140</td>\n",
       "      <td>-38.76478</td>\n",
       "      <td>-0.06844</td>\n",
       "      <td>-0.00653</td>\n",
       "      <td>-0.00463</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.71961</td>\n",
       "      <td>103.43369</td>\n",
       "      <td>0.62848</td>\n",
       "      <td>-0.03600</td>\n",
       "      <td>316.98975</td>\n",
       "      <td>46.56124</td>\n",
       "      <td>-122.69421</td>\n",
       "      <td>8149.62158</td>\n",
       "      <td>23456.24609</td>\n",
       "      <td>2437.16772</td>\n",
       "      <td>-6855.40918</td>\n",
       "      <td>-36.47029</td>\n",
       "      <td>-0.57554</td>\n",
       "      <td>-38.74413</td>\n",
       "      <td>-0.05645</td>\n",
       "      <td>-0.00832</td>\n",
       "      <td>-0.00633</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.80210</td>\n",
       "      <td>103.37489</td>\n",
       "      <td>0.83224</td>\n",
       "      <td>-0.04432</td>\n",
       "      <td>317.00247</td>\n",
       "      <td>46.56127</td>\n",
       "      <td>-122.69424</td>\n",
       "      <td>8149.43262</td>\n",
       "      <td>23453.23828</td>\n",
       "      <td>2437.11768</td>\n",
       "      <td>-6858.60400</td>\n",
       "      <td>-36.44852</td>\n",
       "      <td>-0.62677</td>\n",
       "      <td>-38.72172</td>\n",
       "      <td>-0.04408</td>\n",
       "      <td>-0.00867</td>\n",
       "      <td>-0.00709</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.89681</td>\n",
       "      <td>103.29092</td>\n",
       "      <td>1.05690</td>\n",
       "      <td>-0.05146</td>\n",
       "      <td>317.01611</td>\n",
       "      <td>46.56130</td>\n",
       "      <td>-122.69429</td>\n",
       "      <td>8149.20410</td>\n",
       "      <td>23449.78711</td>\n",
       "      <td>2437.05688</td>\n",
       "      <td>-6862.26953</td>\n",
       "      <td>-36.41737</td>\n",
       "      <td>-0.65032</td>\n",
       "      <td>-38.68958</td>\n",
       "      <td>-0.03029</td>\n",
       "      <td>-0.00876</td>\n",
       "      <td>-0.00772</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7790</th>\n",
       "      <td>677.01807</td>\n",
       "      <td>102.64950</td>\n",
       "      <td>5.03510</td>\n",
       "      <td>-15.52756</td>\n",
       "      <td>92.21129</td>\n",
       "      <td>46.76450</td>\n",
       "      <td>-122.64340</td>\n",
       "      <td>10524.41309</td>\n",
       "      <td>27253.54688</td>\n",
       "      <td>3081.13818</td>\n",
       "      <td>-29478.54102</td>\n",
       "      <td>52.76324</td>\n",
       "      <td>2.18193</td>\n",
       "      <td>2.32113</td>\n",
       "      <td>0.01481</td>\n",
       "      <td>-0.03281</td>\n",
       "      <td>-0.00584</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7791</th>\n",
       "      <td>677.11859</td>\n",
       "      <td>102.61120</td>\n",
       "      <td>5.03769</td>\n",
       "      <td>-15.75969</td>\n",
       "      <td>91.90834</td>\n",
       "      <td>46.76450</td>\n",
       "      <td>-122.64333</td>\n",
       "      <td>10525.20117</td>\n",
       "      <td>27258.84961</td>\n",
       "      <td>3081.35693</td>\n",
       "      <td>-29478.32422</td>\n",
       "      <td>52.75458</td>\n",
       "      <td>2.17173</td>\n",
       "      <td>2.05556</td>\n",
       "      <td>0.01505</td>\n",
       "      <td>-0.03179</td>\n",
       "      <td>-0.00577</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7792</th>\n",
       "      <td>677.21912</td>\n",
       "      <td>102.57314</td>\n",
       "      <td>5.04044</td>\n",
       "      <td>-15.98804</td>\n",
       "      <td>91.60071</td>\n",
       "      <td>46.76449</td>\n",
       "      <td>-122.64326</td>\n",
       "      <td>10525.98730</td>\n",
       "      <td>27264.15039</td>\n",
       "      <td>3081.57471</td>\n",
       "      <td>-29478.13281</td>\n",
       "      <td>52.74484</td>\n",
       "      <td>2.16175</td>\n",
       "      <td>1.78573</td>\n",
       "      <td>0.01529</td>\n",
       "      <td>-0.03097</td>\n",
       "      <td>-0.00570</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7793</th>\n",
       "      <td>677.31958</td>\n",
       "      <td>102.53516</td>\n",
       "      <td>5.04336</td>\n",
       "      <td>-16.21258</td>\n",
       "      <td>91.28848</td>\n",
       "      <td>46.76449</td>\n",
       "      <td>-122.64320</td>\n",
       "      <td>10526.76953</td>\n",
       "      <td>27269.45117</td>\n",
       "      <td>3081.79126</td>\n",
       "      <td>-29477.96875</td>\n",
       "      <td>52.73388</td>\n",
       "      <td>2.15198</td>\n",
       "      <td>1.51168</td>\n",
       "      <td>0.01552</td>\n",
       "      <td>-0.02800</td>\n",
       "      <td>-0.00564</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7794</th>\n",
       "      <td>677.45129</td>\n",
       "      <td>102.48391</td>\n",
       "      <td>5.04739</td>\n",
       "      <td>-16.50119</td>\n",
       "      <td>90.87262</td>\n",
       "      <td>46.76449</td>\n",
       "      <td>-122.64310</td>\n",
       "      <td>10527.79102</td>\n",
       "      <td>27276.39258</td>\n",
       "      <td>3082.07373</td>\n",
       "      <td>-29477.79492</td>\n",
       "      <td>52.71768</td>\n",
       "      <td>2.13947</td>\n",
       "      <td>1.14636</td>\n",
       "      <td>0.01582</td>\n",
       "      <td>-0.02780</td>\n",
       "      <td>-0.00559</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7795 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      _totl,_time  Vtrue,_ktgs  pitch,__deg  _roll,__deg  hding,_true  \\\n",
       "0         5.48427    103.49908      0.07651     -0.00486    316.95850   \n",
       "1         5.60311    103.48605      0.33557     -0.02232    316.97202   \n",
       "2         5.71961    103.43369      0.62848     -0.03600    316.98975   \n",
       "3         5.80210    103.37489      0.83224     -0.04432    317.00247   \n",
       "4         5.89681    103.29092      1.05690     -0.05146    317.01611   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "7790    677.01807    102.64950      5.03510    -15.52756     92.21129   \n",
       "7791    677.11859    102.61120      5.03769    -15.75969     91.90834   \n",
       "7792    677.21912    102.57314      5.04044    -15.98804     91.60071   \n",
       "7793    677.31958    102.53516      5.04336    -16.21258     91.28848   \n",
       "7794    677.45129    102.48391      5.04739    -16.50119     90.87262   \n",
       "\n",
       "      __lat,__deg  __lon,__deg  ___CG,ftMSL  ____X,____m  ____Y,____m  \\\n",
       "0        46.56116   -122.69409   8150.02539  23464.83203   2437.26929   \n",
       "1        46.56120   -122.69415   8149.85596  23460.49609   2437.22852   \n",
       "2        46.56124   -122.69421   8149.62158  23456.24609   2437.16772   \n",
       "3        46.56127   -122.69424   8149.43262  23453.23828   2437.11768   \n",
       "4        46.56130   -122.69429   8149.20410  23449.78711   2437.05688   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "7790     46.76450   -122.64340  10524.41309  27253.54688   3081.13818   \n",
       "7791     46.76450   -122.64333  10525.20117  27258.84961   3081.35693   \n",
       "7792     46.76449   -122.64326  10525.98730  27264.15039   3081.57471   \n",
       "7793     46.76449   -122.64320  10526.76953  27269.45117   3081.79126   \n",
       "7794     46.76449   -122.64310  10527.79102  27276.39258   3082.07373   \n",
       "\n",
       "      ____Z,____m  ___vX,__m/s  ___vY,__m/s  ___vZ,__m/s  _elev,stick  \\\n",
       "0     -6846.28711    -36.49474     -0.21043    -38.77045     -0.04573   \n",
       "1     -6850.89453    -36.49013     -0.44140    -38.76478     -0.06844   \n",
       "2     -6855.40918    -36.47029     -0.57554    -38.74413     -0.05645   \n",
       "3     -6858.60400    -36.44852     -0.62677    -38.72172     -0.04408   \n",
       "4     -6862.26953    -36.41737     -0.65032    -38.68958     -0.03029   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "7790 -29478.54102     52.76324      2.18193      2.32113      0.01481   \n",
       "7791 -29478.32422     52.75458      2.17173      2.05556      0.01505   \n",
       "7792 -29478.13281     52.74484      2.16175      1.78573      0.01529   \n",
       "7793 -29477.96875     52.73388      2.15198      1.51168      0.01552   \n",
       "7794 -29477.79492     52.71768      2.13947      1.14636      0.01582   \n",
       "\n",
       "      ailrn,stick  ruddr,stick  thro1,engin  \n",
       "0         0.00032     -0.00179      0.62949  \n",
       "1        -0.00653     -0.00463      0.00000  \n",
       "2        -0.00832     -0.00633      0.00000  \n",
       "3        -0.00867     -0.00709      0.00000  \n",
       "4        -0.00876     -0.00772      0.00000  \n",
       "...           ...          ...          ...  \n",
       "7790     -0.03281     -0.00584      1.00000  \n",
       "7791     -0.03179     -0.00577      1.00000  \n",
       "7792     -0.03097     -0.00570      1.00000  \n",
       "7793     -0.02800     -0.00564      1.00000  \n",
       "7794     -0.02780     -0.00559      1.00000  \n",
       "\n",
       "[7795 rows x 18 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#relevent columes\n",
    "\n",
    "relevent_features = ['_totl,_time','Vtrue,_ktgs','pitch,__deg','_roll,__deg','hding,_true','__lat,__deg','__lon,__deg','___CG,ftMSL','____X,____m','____Y,____m','____Z,____m','___vX,__m/s','___vY,__m/s','___vZ,__m/s'\n",
    "                     ,'_elev,stick','ailrn,stick','ruddr,stick','thro1,engin'\n",
    "]\n",
    "\n",
    "train_data = pd.read_csv('data/Data4.csv')\n",
    "train_data = train_data.dropna(axis=1, how='all')\n",
    "train_data = train_data[relevent_features]\n",
    "train_data\n",
    "\n",
    "val_data = pd.read_csv('data/Data3.csv')\n",
    "val_data = val_data.dropna(axis=1, how='all')\n",
    "val_data = val_data[relevent_features]\n",
    "val_data\n",
    "\n",
    "test_data = pd.read_csv('data/Data2.csv')\n",
    "test_data = test_data.dropna(axis=1, how='all')\n",
    "test_data = test_data[relevent_features]\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATING A MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlightDataset(Dataset):\n",
    "    def __init__(self, df, seq_len, scaler=None):\n",
    "        # Keeping only the relevant features\n",
    "        relevant_features = ['_totl,_time','Vtrue,_ktgs','pitch,__deg','_roll,__deg','hding,_true','__lat,__deg','__lon,__deg','___CG,ftMSL','____X,____m','____Y,____m','____Z,____m','___vX,__m/s','___vY,__m/s','___vZ,__m/s'\n",
    "                     ,'_elev,stick','ailrn,stick','ruddr,stick','thro1,engin'\n",
    "]\n",
    "        \n",
    "        self.df = df[relevant_features].copy()  # Use copy to avoid modifying the original DataFrame\n",
    "\n",
    "        # Changing the names of the features for easier use\n",
    "        self.df.columns = ['time', 'vt', 'pitch', 'roll', 'hding', 'lat', 'lon', 'alt', 'x', 'y', 'z', 'vx', 'vy', 'vz', 'elev_stick', 'ailrn_stick', 'ruddr_stick', 'throttle']\n",
    "        \n",
    "        if scaler is None:\n",
    "            self.scaler = StandardScaler()\n",
    "            self.df = pd.DataFrame(self.scaler.fit_transform(self.df), columns=self.df.columns)\n",
    "        else:\n",
    "            self.scaler = scaler\n",
    "            self.df = pd.DataFrame(self.scaler.transform(self.df), columns=self.df.columns)\n",
    "        \n",
    "        # Define sequence length\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        # Making the length shorter by seq_len so we always have a next_state\n",
    "        return len(self.df) - 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < self.seq_len:\n",
    "            padding = np.zeros((self.seq_len - idx, len(self.df.columns)))\n",
    "            current_state = np.vstack((padding, self.df.iloc[:idx].values.astype(float)))\n",
    "        else:\n",
    "            current_state = self.df.iloc[idx - self.seq_len:idx].values.astype(float)\n",
    "            \n",
    "        # Next state is the state at idx + seq_len\n",
    "        next_state = self.df.iloc[idx + 1][['vt', 'pitch', 'roll', 'hding', 'lat', 'lon', 'alt', 'x', 'y', 'z', 'vx', 'vy', 'vz']].values.astype(float)\n",
    "        full_next_state = self.df.iloc[idx + 1][['time', 'vt', 'pitch', 'roll', 'hding', 'lat', 'lon', 'alt', 'x', 'y', 'z', 'vx', 'vy', 'vz', 'elev_stick', 'ailrn_stick', 'ruddr_stick', 'throttle']].values.astype(float)\n",
    "        return torch.tensor(current_state, dtype=torch.float32), torch.tensor(next_state, dtype=torch.float32), torch.tensor(full_next_state, dtype=torch.float32)\n",
    "    \n",
    "    def inverse_transform(self, data):\n",
    "        return self.scaler.inverse_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlightLSTM(pl.LightningModule):\n",
    "    def __init__(self,input_dim,hidden_dim,num_layers,output_dim,lr=0.001):\n",
    "        super(FlightLSTM,self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim,hidden_dim,num_layers,batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.lr = lr\n",
    "        self.criterion = nn.MSELoss(reduction='none')\n",
    "\n",
    "        self.training_step_outputs = []\n",
    "        self.validation_step_outputs = []\n",
    "        self.test_step_outputs = []\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out,_ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "    def compute_metrics(self, y_true, y_pred):\n",
    "        mse = np.mean((y_true - y_pred) ** 2, axis=0)\n",
    "        mae = np.mean(np.abs(y_true - y_pred), axis=0)\n",
    "        return mse, mae\n",
    "        \n",
    "\n",
    "    def physics_loss(self, x, y, y_pred):\n",
    "        \"\"\"\n",
    "        Calculate the physics-based loss for the given predictions.\n",
    "\n",
    "        Args:\n",
    "        - x: Input tensor (shape: [batch_size, seq_len, num_features]).\n",
    "        - y: Target tensor (shape: [batch_size, num_output_features]).\n",
    "        - y_pred: Predicted tensor (shape: [batch_size, num_output_features]).\n",
    "\n",
    "        Returns:\n",
    "        - loss: Physics-based loss (scalar).\n",
    "        \"\"\"\n",
    "        m = 1127.177  # Total mass of the Cessna Skyhawk in kg\n",
    "\n",
    "        def compute_velocities(time):\n",
    "            out, _ = self.lstm(x)\n",
    "            out = self.fc(out[:, -1, :])\n",
    "            vx_pred = out[:, 6]\n",
    "            vy_pred = out[:, 7]\n",
    "            vz_pred = out[:, 8]\n",
    "            return vx_pred, vy_pred, vz_pred\n",
    "        \n",
    "        def compute_actual_velocities(time):\n",
    "            vx_actual = y[:, 6]\n",
    "            vy_actual = y[:, 7]\n",
    "            vz_actual = y[:, 8]\n",
    "            return vx_actual, vy_actual, vz_actual\n",
    "\n",
    "        # Extract the relevant features from y_pred\n",
    "        vx_pred = y_pred[:, 6]\n",
    "        vy_pred = y_pred[:, 7]\n",
    "        vz_pred = y_pred[:, 8]\n",
    "        pitch_pred = y_pred[:, 3]\n",
    "        roll_pred = y_pred[:, 4]\n",
    "        hding_pred = y_pred[:, 5]\n",
    "        # Extract time feature\n",
    "        time = x[:, :, 0]  # Assuming index 0 corresponds to 'time'\n",
    "        time.requires_grad_(True)\n",
    "        # Calculate derivatives with respect to time for the predicted velocities\n",
    "        vx_pred, vy_pred, vz_pred = compute_velocities(time)\n",
    "        jacobians = F.jacobian(compute_velocities, time, create_graph=True, strict=False, vectorize=True)\n",
    "        dvx_dt_pred, dvy_dt_pred, dvz_dt_pred = jacobians\n",
    "\n",
    "        vx_pred = vx_pred.unsqueeze(1).unsqueeze(2)  # Shape: [64, 1, 1]\n",
    "        vy_pred = vy_pred.unsqueeze(1).unsqueeze(2)  # Shape: [64, 1, 1]\n",
    "        vz_pred = vz_pred.unsqueeze(1).unsqueeze(2)  # Shape: [64, 1, 1]\n",
    "\n",
    "        pitch_pred = pitch_pred.unsqueeze(1).unsqueeze(2)  # Shape: [64, 1, 1]\n",
    "        roll_pred = roll_pred.unsqueeze(1).unsqueeze(2)    # Shape: [64, 1, 1]\n",
    "        hding_pred = hding_pred.unsqueeze(1).unsqueeze(2)  # Shape: [64, 1, 1]\n",
    "\n",
    "        \n",
    "        # Calculate predicted forces\n",
    "        X_pred = m * (dvx_dt_pred + pitch_pred * vz_pred - hding_pred * vy_pred)\n",
    "        Y_pred = m * (dvy_dt_pred + hding_pred * vx_pred - roll_pred * vz_pred)\n",
    "        Z_pred = m * (dvz_dt_pred + roll_pred * vy_pred - pitch_pred * vx_pred)\n",
    "\n",
    "        # Extract the relevant features from y\n",
    "        pitch_actual = y[:, 3]  # Index 3 corresponds to 'pitch'\n",
    "        roll_actual = y[:, 4]  # Index 4 corresponds to 'roll'\n",
    "        hding_actual = y[:, 5]  # Index 5 corresponds to 'hding'\n",
    "        vx_actual = y[:, 6]\n",
    "        vy_actual = y[:, 7]\n",
    "        vz_actual = y[:, 8]\n",
    "\n",
    "        # Calculate derivatives with respect to time for the actual velocities\n",
    "        vx_actual, vy_actual, vz_actual = compute_actual_velocities(time)\n",
    "        jacobians_actual = F.jacobian(compute_actual_velocities, time, create_graph=True, strict=False, vectorize=True)\n",
    "        dvx_dt_actual, dvy_dt_actual, dvz_dt_actual = jacobians_actual\n",
    "\n",
    "        vx_actual = vx_actual.unsqueeze(1).unsqueeze(2)  # Shape: [64, 1, 1]\n",
    "        vy_actual = vy_actual.unsqueeze(1).unsqueeze(2)  # Shape: [64, 1, 1]\n",
    "        vz_actual = vz_actual.unsqueeze(1).unsqueeze(2)  # Shape: [64, 1, 1]\n",
    "\n",
    "        pitch_actual = pitch_actual.unsqueeze(1).unsqueeze(2)  # Shape: [64, 1, 1]\n",
    "        roll_actual = roll_actual.unsqueeze(1).unsqueeze(2)    # Shape: [64, 1, 1]\n",
    "        hding_actual = hding_actual.unsqueeze(1).unsqueeze(2)  # Shape: [64, 1, 1]\n",
    "\n",
    "        # Calculate actual forces\n",
    "        X_actual = m * (dvx_dt_actual + pitch_actual * vz_actual - hding_actual * vy_actual)\n",
    "        Y_actual = m * (dvy_dt_actual + hding_actual * vx_actual - roll_actual * vz_actual)\n",
    "        Z_actual = m * (dvz_dt_actual + roll_actual * vy_actual - pitch_actual * vx_actual)\n",
    "\n",
    "        # Compute physics-based loss\n",
    "        loss_X = torch.mean((X_pred - X_actual) ** 2)\n",
    "        loss_Y = torch.mean((Y_pred - Y_actual) ** 2)\n",
    "        loss_Z = torch.mean((Z_pred - Z_actual) ** 2)\n",
    "\n",
    "        physics_loss = loss_X + loss_Y + loss_Z\n",
    "        return physics_loss\n",
    "\n",
    "        \n",
    "    \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        x, y ,_ = batch\n",
    "        output = self(x)\n",
    "        mse_loss = self.criterion(output, y).mean()\n",
    "        phys_loss = self.physics_loss(x, y, output)\n",
    "        loss = mse_loss + phys_loss\n",
    "        self.log(\"train/batch/loss\", loss, prog_bar=False)\n",
    "\n",
    "        y_true = y.cpu().detach().numpy()\n",
    "        y_pred = output.cpu().detach().numpy()\n",
    "\n",
    "        mse, mae = self.compute_metrics(y_true, y_pred)\n",
    "\n",
    "        for i, feature in enumerate(['lat', 'lon', 'alt', 'pitch', 'roll', 'hding', 'vx', 'vy', 'vz']):\n",
    "            self.log(f\"train/batch/mse_{feature}\", mse[i], prog_bar=False)\n",
    "            self.log(f\"train/batch/mae_{feature}\", mae[i], prog_bar=False)\n",
    "\n",
    "        self.training_step_outputs.append({\"loss\": loss, \"mse\": mse, \"mae\": mae, \"y_true\": y_true, \"y_pred\": y_pred})\n",
    "\n",
    "        return {\"loss\": loss, \"mse\": mse, \"mae\": mae}\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        loss = np.array([output[\"loss\"].detach().cpu().numpy() for output in self.training_step_outputs])\n",
    "        mse = np.vstack([output[\"mse\"] for output in self.training_step_outputs])\n",
    "        mae = np.vstack([output[\"mae\"] for output in self.training_step_outputs])\n",
    "\n",
    "        y_true_all = np.vstack([output[\"y_true\"] for output in self.training_step_outputs])\n",
    "        y_pred_all = np.vstack([output[\"y_pred\"] for output in self.training_step_outputs])\n",
    "\n",
    "        mse_all = np.mean(mse, axis=0)\n",
    "        mae_all = np.mean(mae, axis=0)\n",
    "        r2_all = r2_score(y_true_all, y_pred_all)\n",
    "\n",
    "        self.log(\"train/epoch/loss\", loss.mean())  # Log training epoch loss\n",
    "        for i, feature in enumerate(['lat', 'lon', 'alt', 'pitch', 'roll', 'hding', 'vx', 'vy', 'vz']):\n",
    "            self.log(f\"train/epoch/mse_{feature}\", mse_all[i])  # Log training epoch MSE for each feature\n",
    "            self.log(f\"train/epoch/mae_{feature}\", mae_all[i])  # Log training epoch MAE for each feature\n",
    "        self.log(\"train/epoch/r2\", r2_all)  # Log training epoch R²\n",
    "\n",
    "\n",
    "        print(\"Training Epoch End: Loss:\", loss.mean(), \"MSE:\", mse_all, \"MAE:\", mae_all, \"R²:\", r2_all)  # Debugging print\n",
    "        \n",
    "        self.training_step_outputs.clear()\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, y_full = batch\n",
    "        output = self.rolling_prediction(x[0], y_full)\n",
    "        mse_loss = self.criterion(output, y).mean()\n",
    "        phys_loss = self.physics_loss(x, y, output)\n",
    "        loss = mse_loss + phys_loss\n",
    "\n",
    "        y_true = y.cpu().detach().numpy()\n",
    "        y_pred = output.cpu().detach().numpy()\n",
    "\n",
    "        mse, mae = self.compute_metrics(y_true, y_pred)\n",
    "\n",
    "        for i, feature in enumerate(['lat', 'lon', 'alt', 'pitch', 'roll', 'hding', 'vx', 'vy', 'vz']):\n",
    "            self.log(f\"val/batch/mse_{feature}\", mse[i], prog_bar=False)\n",
    "            self.log(f\"val/batch/mae_{feature}\", mae[i], prog_bar=False)\n",
    "\n",
    "        self.validation_step_outputs.append({\"loss\": loss, \"mse\": mse, \"mae\": mae, \"y_true\": y_true, \"y_pred\": y_pred})\n",
    "\n",
    "        return {\"loss\": loss, \"mse\": mse, \"mae\": mae}\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        loss = np.array([output[\"loss\"].detach().cpu().numpy() for output in self.validation_step_outputs])\n",
    "        mse = np.vstack([output[\"mse\"] for output in self.validation_step_outputs])\n",
    "        mae = np.vstack([output[\"mae\"] for output in self.validation_step_outputs])\n",
    "\n",
    "        y_true_all = np.vstack([output[\"y_true\"] for output in self.validation_step_outputs])\n",
    "        y_pred_all = np.vstack([output[\"y_pred\"] for output in self.validation_step_outputs])\n",
    "\n",
    "        mse_all = np.mean(mse, axis=0)\n",
    "        mae_all = np.mean(mae, axis=0)\n",
    "        r2_all = r2_score(y_true_all, y_pred_all)\n",
    "\n",
    "        self.log(\"val/epoch/loss\", loss.mean())  # Log validation epoch loss\n",
    "        for i, feature in enumerate(['lat', 'lon', 'alt', 'pitch', 'roll', 'hding', 'vx', 'vy', 'vz']):\n",
    "            self.log(f\"val/epoch/mse_{feature}\", mse_all[i])  # Log validation epoch MSE for each feature\n",
    "            self.log(f\"val/epoch/mae_{feature}\", mae_all[i])  # Log validation epoch MAE for each feature\n",
    "        self.log(\"val/epoch/r2\", r2_all)  # Log validation epoch R²\n",
    "\n",
    "        print(\"Validation Epoch End: Loss:\", loss.mean(), \"MSE:\", mse_all, \"MAE:\", mae_all, \"R²:\", r2_all)  # Debugging print\n",
    "\n",
    "        self.validation_step_outputs.clear()  # free memory\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y, y_full = batch\n",
    "        output = self.rolling_prediction(x[0], y_full)\n",
    "        loss = self.criterion(output, y).mean()\n",
    "\n",
    "        y_true = y.cpu().detach().numpy()\n",
    "        y_pred = output.cpu().detach().numpy()\n",
    "\n",
    "        mse, mae = self.compute_metrics(y_true, y_pred)\n",
    "\n",
    "        for i, feature in enumerate(['lat', 'lon', 'alt', 'pitch', 'roll', 'hding', 'vx', 'vy', 'vz']):\n",
    "            self.log(f\"test/batch/mse_{feature}\", mse[i], prog_bar=False)\n",
    "            self.log(f\"test/batch/mae_{feature}\", mae[i], prog_bar=False)\n",
    "\n",
    "        self.test_step_outputs.append({\"loss\": loss, \"mse\": mse, \"mae\": mae, \"y_true\": y_true, \"y_pred\": y_pred})\n",
    "\n",
    "        return {\"loss\": loss, \"mse\": mse, \"mae\": mae}\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        loss = np.array([output[\"loss\"].detach().cpu().numpy() for output in self.test_step_outputs])\n",
    "        mse = np.vstack([output[\"mse\"] for output in self.test_step_outputs])\n",
    "        mae = np.vstack([output[\"mae\"] for output in self.test_step_outputs])\n",
    "\n",
    "        y_true_all = np.vstack([output[\"y_true\"] for output in self.test_step_outputs])\n",
    "        y_pred_all = np.vstack([output[\"y_pred\"] for output in self.test_step_outputs])\n",
    "\n",
    "        mse_all = np.mean(mse, axis=0)\n",
    "        mae_all = np.mean(mae, axis=0)\n",
    "        r2_all = r2_score(y_true_all, y_pred_all)\n",
    "\n",
    "        self.log(\"test/epoch/loss\", loss.mean())  # Log test epoch loss\n",
    "        for i, feature in enumerate(['lat', 'lon', 'alt', 'pitch', 'roll', 'hding', 'vx', 'vy', 'vz']):\n",
    "            self.log(f\"test/epoch/mse_{feature}\", mse_all[i])  # Log test epoch MSE for each feature\n",
    "            self.log(f\"test/epoch/mae_{feature}\", mae_all[i])  # Log test epoch MAE for each feature\n",
    "        self.log(\"test/epoch/r2\", r2_all)  # Log test epoch R²\n",
    "\n",
    "        print(\"Test Epoch End: Loss:\", loss.mean(), \"MSE:\", mse_all, \"MAE:\", mae_all, \"R²:\", r2_all)  # Debugging print\n",
    "\n",
    "        self.test_step_outputs.clear()  # free memory\n",
    "\n",
    "    def save_predictions_to_csv(self, test_data):\n",
    "        predictions = []\n",
    "        actual_data = []\n",
    "        \n",
    "        for batch in test_data:\n",
    "            x, y = batch\n",
    "            output = self.forward(x)\n",
    "            predictions.append(output.cpu().detach().numpy())\n",
    "            actual_data.append(y.cpu().detach().numpy())\n",
    "            \n",
    "        predictions = np.vstack(predictions)\n",
    "        actual_data = np.vstack(actual_data)\n",
    "\n",
    "        # Use the scaler to inverse transform only the predictions and actuals, ensuring alignment with the scaler's feature order\n",
    "        num_samples = predictions.shape[0]\n",
    "        all_features = ['time', 'vt', 'pitch', 'roll', 'hding', 'lat', 'lon', 'alt', 'x', 'y', 'z', 'vx', 'vy', 'vz', 'elev_stick', 'ailrn_stick', 'ruddr_stick', 'throttle']\n",
    "        relevant_indices = [all_features.index(feature) for feature in ['lat', 'lon', 'alt', 'pitch', 'roll', 'hding', 'vx', 'vy', 'vz']]\n",
    "        \n",
    "        # Create a zero matrix with the same shape as the scaler's expected input\n",
    "        padded_predictions = np.zeros((num_samples, len(all_features)))\n",
    "        padded_actual_data = np.zeros((num_samples, len(all_features)))\n",
    "\n",
    "        # Place the predictions and actual data in the correct positions\n",
    "        padded_predictions[:, relevant_indices] = predictions\n",
    "        padded_actual_data[:, relevant_indices] = actual_data\n",
    "\n",
    "        # Inverse transform\n",
    "        scaler = test_data.dataset.scaler\n",
    "        unnormalized_predictions = scaler.inverse_transform(padded_predictions)[:, relevant_indices]\n",
    "        unnormalized_actual_data = scaler.inverse_transform(padded_actual_data)[:, relevant_indices]\n",
    "\n",
    "        # Create dataframes for the unnormalized predictions and actual values\n",
    "        columns = ['lat', 'lon', 'alt', 'pitch', 'roll', 'hding', 'vx', 'vy', 'vz']\n",
    "        predictions_df = pd.DataFrame(unnormalized_predictions, columns=[f'predicted_{col}' for col in columns])\n",
    "        actual_data_df = pd.DataFrame(unnormalized_actual_data, columns=[f'actual_{col}' for col in columns])\n",
    "        \n",
    "        # Combine the dataframes such that each predicted value is next to its corresponding actual value\n",
    "        combined_df = pd.DataFrame()\n",
    "        for col in columns:\n",
    "            combined_df[f'predicted_{col}'] = predictions_df[f'predicted_{col}']\n",
    "            combined_df[f'actual_{col}'] = actual_data_df[f'actual_{col}']\n",
    "        \n",
    "        combined_df.to_csv('test.csv', index=False)\n",
    "\n",
    "\n",
    "    def rolling_prediction(self, initial_sequence, full_y):\n",
    "        \"\"\"\n",
    "        Perform rolling prediction based on the initial sequence and full target sequence.\n",
    "\n",
    "        Args:\n",
    "        - initial_sequence: The initial sequence to start the prediction from (shape: [50, 18]).\n",
    "        - full_y: The full target sequence containing all information (shape: [batch_size, 18]).\n",
    "\n",
    "        Returns:\n",
    "        - predictions: The predicted future states (shape: [batch_size, 13]).\n",
    "        \"\"\"\n",
    "        sequence = initial_sequence  # Initial sequence of shape [50, 18]\n",
    "        predictions = []\n",
    "        batch_size = full_y.size(0)  # Number of steps to predict\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            # Predict the next state\n",
    "            next_state = self(sequence.unsqueeze(0))  # sequence.unsqueeze(0) shape: [1, 50, 18]\n",
    "            next_state = next_state.squeeze(0)  # Prediction of shape [13]\n",
    "\n",
    "            # Extract relevant information from full_y for the current step\n",
    "            full_info = full_y[i]\n",
    "\n",
    "            # Create a new state of shape [18] to maintain the sequence length\n",
    "            new_state = torch.zeros(18, device=sequence.device)\n",
    "\n",
    "            # Assign the predicted values to the appropriate indices in new_state\n",
    "            new_state[1:14] = next_state  # Indices for ['vt', 'pitch', 'roll', 'hding', 'lat', 'lon', 'alt', 'x', 'y', 'z', 'vx', 'vy', 'vz']\n",
    "\n",
    "            # Assign the remaining values from full_info\n",
    "            new_state[0] = full_info[0]  # 'time'\n",
    "            new_state[14:] = full_info[14:]  # Control inputs: 'elev_stick', 'ailrn_stick', 'ruddr_stick', 'throttle'\n",
    "\n",
    "            # Append the new state to the sequence and remove the oldest state\n",
    "            sequence = torch.cat((sequence[1:], new_state.unsqueeze(0)), dim=0)\n",
    "\n",
    "            # Append the prediction to predictions list\n",
    "            predictions.append(next_state)\n",
    "\n",
    "        return torch.stack(predictions)  # Return predictions as a tensor\n",
    "\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "def seed_everything(seed=42):\n",
    "    # random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    pl.seed_everything(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set the seed\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['totl,_time', 'pitch,deg', '_roll,deg', 'lat,deg', 'lon,deg', '_CG,ftMSL', 'X,m', 'Y,m', 'Z,m', '_vX,m/s', '_vY,m/s', '_vZ,_m/s'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m sequance_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m----> 2\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m FlightDataset(train_data, sequance_length)\n\u001b[0;32m      3\u001b[0m fitted_scaler \u001b[38;5;241m=\u001b[39m train_dataset\u001b[38;5;241m.\u001b[39mscaler\n\u001b[0;32m      4\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m FlightDataset(val_data, sequance_length, fitted_scaler)\n",
      "Cell \u001b[1;32mIn[28], line 6\u001b[0m, in \u001b[0;36mFlightDataset.__init__\u001b[1;34m(self, df, seq_len, scaler)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, df, seq_len, scaler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Keeping only the relevant features\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     relevant_features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotl,_time\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVtrue,_ktgs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpitch,deg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_roll,deg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhding,_true\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat,deg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon,deg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_CG,ftMSL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX,m\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY,m\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZ,m\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_vX,m/s\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_vY,m/s\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_vZ,_m/s\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_elev,stick\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mailrn,stick\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mruddr,stick\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthro1,engin\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf \u001b[38;5;241m=\u001b[39m df[relevant_features]\u001b[38;5;241m.\u001b[39mcopy()  \u001b[38;5;66;03m# Use copy to avoid modifying the original DataFrame\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Changing the names of the features for easier use\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpitch\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroll\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhding\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvz\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124melev_stick\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mailrn_stick\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mruddr_stick\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthrottle\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\milne\\PINN\\PINN-module-for-aircraft-simulator\\.conda\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\milne\\PINN\\PINN-module-for-aircraft-simulator\\.conda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\milne\\PINN\\PINN-module-for-aircraft-simulator\\.conda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['totl,_time', 'pitch,deg', '_roll,deg', 'lat,deg', 'lon,deg', '_CG,ftMSL', 'X,m', 'Y,m', 'Z,m', '_vX,m/s', '_vY,m/s', '_vZ,_m/s'] not in index\""
     ]
    }
   ],
   "source": [
    "sequance_length = 20\n",
    "train_dataset = FlightDataset(train_data, sequance_length)\n",
    "fitted_scaler = train_dataset.scaler\n",
    "val_dataset = FlightDataset(val_data, sequance_length, fitted_scaler)\n",
    "test_dataset = FlightDataset(test_data, sequance_length, fitted_scaler)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming train_loader is your dataloader\n",
    "for batch in train_loader:\n",
    "    # Unpack the batch (assuming it contains inputs and targets)\n",
    "    inputs, targets = batch\n",
    "    \n",
    "    # Print the inputs and targets to understand their structure\n",
    "    print(\"Inputs: \", inputs)\n",
    "    print(\"Targets: \", targets)\n",
    "    \n",
    "    # Print the size of the inputs\n",
    "    print(\"Size of inputs: \", inputs.size())\n",
    "    \n",
    "    # Break the loop after the first batch\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neptune_logger = NeptuneLogger(\n",
    "    api_key=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI4ZGJmNTQyNy04OWFhLTQ0YzMtYTA5Ni1hNTc1NjJmMGYxMjkifQ==\",\n",
    "    project=\"kapustya/example-project-tensorflow-keras\",\n",
    "    tags=[\"test\"],\n",
    "    log_model_checkpoints=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything()\n",
    "torch.set_grad_enabled(True)\n",
    "input_dim = len(train_data.columns)\n",
    "hidden_dim = 128\n",
    "num_layers = 2\n",
    "output_dim = 13\n",
    "model = FlightLSTM(input_dim, hidden_dim, num_layers, output_dim)\n",
    "trainer = pl.Trainer(\n",
    "    logger = neptune_logger,\n",
    "    max_epochs=3\n",
    "    )\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "trainer.test(model, test_loader)\n",
    "model.save_predictions_to_csv(test_loader)\n",
    "neptune_logger.experiment.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PinnProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
