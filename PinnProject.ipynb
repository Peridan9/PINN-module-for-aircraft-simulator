{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import lightning as L\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import BatchSizeFinder, LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import NeptuneLogger\n",
    "import neptune\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and PreProcessing the Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "txt to csv if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "\n",
    "# name_open = 'Data.txt'\n",
    "# name_new = 'datatest2.csv'\n",
    "# delimiter = '|'  # Adjust this if your actual delimiter is different\n",
    "\n",
    "# # Read from text file and write to CSV file\n",
    "# with open(name_open, 'r') as f:\n",
    "#     # Read the lines\n",
    "#     lines = f.readlines()\n",
    "\n",
    "# # Extract headers from the first line\n",
    "# headers = [header.strip() for header in lines[0].split(delimiter)]\n",
    "\n",
    "# # Open a new CSV file to write the data\n",
    "# with open(name_new, 'w', newline='') as csvfile:\n",
    "#     writer = csv.writer(csvfile, escapechar='\\\\')  # Specify escapechar to handle special characters\n",
    "    \n",
    "#     # Write headers\n",
    "#     writer.writerow(headers)\n",
    "\n",
    "#     # Write rows\n",
    "#     for line in lines[1:]:\n",
    "#         row = [item.strip() for item in line.split(delimiter)]\n",
    "#         writer.writerow(row)\n",
    "\n",
    "# print(f\"Conversion completed. Data written to {name_new}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_totl,_time</th>\n",
       "      <th>Vtrue,_ktgs</th>\n",
       "      <th>pitch,__deg</th>\n",
       "      <th>_roll,__deg</th>\n",
       "      <th>hding,_true</th>\n",
       "      <th>__lat,__deg</th>\n",
       "      <th>__lon,__deg</th>\n",
       "      <th>___CG,ftMSL</th>\n",
       "      <th>____X,____m</th>\n",
       "      <th>____Y,____m</th>\n",
       "      <th>____Z,____m</th>\n",
       "      <th>___vX,__m/s</th>\n",
       "      <th>___vY,__m/s</th>\n",
       "      <th>___vZ,__m/s</th>\n",
       "      <th>_elev,stick</th>\n",
       "      <th>ailrn,stick</th>\n",
       "      <th>ruddr,stick</th>\n",
       "      <th>thro1,engin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05025</td>\n",
       "      <td>0.08962</td>\n",
       "      <td>2.50369</td>\n",
       "      <td>0.02244</td>\n",
       "      <td>92.61546</td>\n",
       "      <td>45.72394</td>\n",
       "      <td>-122.55013</td>\n",
       "      <td>292.82214</td>\n",
       "      <td>35021.74609</td>\n",
       "      <td>-56.05212</td>\n",
       "      <td>-24987.36914</td>\n",
       "      <td>-0.01215</td>\n",
       "      <td>0.05113</td>\n",
       "      <td>0.00660</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.14557</td>\n",
       "      <td>0.13320</td>\n",
       "      <td>2.78831</td>\n",
       "      <td>0.09394</td>\n",
       "      <td>92.62069</td>\n",
       "      <td>45.72394</td>\n",
       "      <td>-122.55013</td>\n",
       "      <td>292.83615</td>\n",
       "      <td>35021.74219</td>\n",
       "      <td>-56.04783</td>\n",
       "      <td>-24987.36719</td>\n",
       "      <td>-0.06101</td>\n",
       "      <td>0.03080</td>\n",
       "      <td>0.01416</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.24257</td>\n",
       "      <td>0.15175</td>\n",
       "      <td>3.15759</td>\n",
       "      <td>0.17618</td>\n",
       "      <td>92.62554</td>\n",
       "      <td>45.72394</td>\n",
       "      <td>-122.55013</td>\n",
       "      <td>292.83878</td>\n",
       "      <td>35021.73438</td>\n",
       "      <td>-56.04699</td>\n",
       "      <td>-24987.36719</td>\n",
       "      <td>-0.07731</td>\n",
       "      <td>-0.00651</td>\n",
       "      <td>0.01524</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.32532</td>\n",
       "      <td>0.15559</td>\n",
       "      <td>3.47054</td>\n",
       "      <td>0.23833</td>\n",
       "      <td>92.62866</td>\n",
       "      <td>45.72394</td>\n",
       "      <td>-122.55013</td>\n",
       "      <td>292.83459</td>\n",
       "      <td>35021.72656</td>\n",
       "      <td>-56.04823</td>\n",
       "      <td>-24987.36523</td>\n",
       "      <td>-0.07660</td>\n",
       "      <td>-0.01822</td>\n",
       "      <td>0.01317</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.41103</td>\n",
       "      <td>0.15037</td>\n",
       "      <td>3.77623</td>\n",
       "      <td>0.29061</td>\n",
       "      <td>92.62982</td>\n",
       "      <td>45.72394</td>\n",
       "      <td>-122.55013</td>\n",
       "      <td>292.82932</td>\n",
       "      <td>35021.72266</td>\n",
       "      <td>-56.04979</td>\n",
       "      <td>-24987.36523</td>\n",
       "      <td>-0.07464</td>\n",
       "      <td>-0.01758</td>\n",
       "      <td>0.00869</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7848</th>\n",
       "      <td>677.01807</td>\n",
       "      <td>102.64950</td>\n",
       "      <td>5.03510</td>\n",
       "      <td>-15.52756</td>\n",
       "      <td>92.21129</td>\n",
       "      <td>46.76450</td>\n",
       "      <td>-122.64340</td>\n",
       "      <td>10524.41309</td>\n",
       "      <td>27253.54688</td>\n",
       "      <td>3081.13818</td>\n",
       "      <td>-29478.54102</td>\n",
       "      <td>52.76324</td>\n",
       "      <td>2.18193</td>\n",
       "      <td>2.32113</td>\n",
       "      <td>0.01481</td>\n",
       "      <td>-0.03281</td>\n",
       "      <td>-0.00584</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7849</th>\n",
       "      <td>677.11859</td>\n",
       "      <td>102.61120</td>\n",
       "      <td>5.03769</td>\n",
       "      <td>-15.75969</td>\n",
       "      <td>91.90834</td>\n",
       "      <td>46.76450</td>\n",
       "      <td>-122.64333</td>\n",
       "      <td>10525.20117</td>\n",
       "      <td>27258.84961</td>\n",
       "      <td>3081.35693</td>\n",
       "      <td>-29478.32422</td>\n",
       "      <td>52.75458</td>\n",
       "      <td>2.17173</td>\n",
       "      <td>2.05556</td>\n",
       "      <td>0.01505</td>\n",
       "      <td>-0.03179</td>\n",
       "      <td>-0.00577</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7850</th>\n",
       "      <td>677.21912</td>\n",
       "      <td>102.57314</td>\n",
       "      <td>5.04044</td>\n",
       "      <td>-15.98804</td>\n",
       "      <td>91.60071</td>\n",
       "      <td>46.76449</td>\n",
       "      <td>-122.64326</td>\n",
       "      <td>10525.98730</td>\n",
       "      <td>27264.15039</td>\n",
       "      <td>3081.57471</td>\n",
       "      <td>-29478.13281</td>\n",
       "      <td>52.74484</td>\n",
       "      <td>2.16175</td>\n",
       "      <td>1.78573</td>\n",
       "      <td>0.01529</td>\n",
       "      <td>-0.03097</td>\n",
       "      <td>-0.00570</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7851</th>\n",
       "      <td>677.31958</td>\n",
       "      <td>102.53516</td>\n",
       "      <td>5.04336</td>\n",
       "      <td>-16.21258</td>\n",
       "      <td>91.28848</td>\n",
       "      <td>46.76449</td>\n",
       "      <td>-122.64320</td>\n",
       "      <td>10526.76953</td>\n",
       "      <td>27269.45117</td>\n",
       "      <td>3081.79126</td>\n",
       "      <td>-29477.96875</td>\n",
       "      <td>52.73388</td>\n",
       "      <td>2.15198</td>\n",
       "      <td>1.51168</td>\n",
       "      <td>0.01552</td>\n",
       "      <td>-0.02800</td>\n",
       "      <td>-0.00564</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7852</th>\n",
       "      <td>677.45129</td>\n",
       "      <td>102.48391</td>\n",
       "      <td>5.04739</td>\n",
       "      <td>-16.50119</td>\n",
       "      <td>90.87262</td>\n",
       "      <td>46.76449</td>\n",
       "      <td>-122.64310</td>\n",
       "      <td>10527.79102</td>\n",
       "      <td>27276.39258</td>\n",
       "      <td>3082.07373</td>\n",
       "      <td>-29477.79492</td>\n",
       "      <td>52.71768</td>\n",
       "      <td>2.13947</td>\n",
       "      <td>1.14636</td>\n",
       "      <td>0.01582</td>\n",
       "      <td>-0.02780</td>\n",
       "      <td>-0.00559</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7853 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      _totl,_time  Vtrue,_ktgs  pitch,__deg  _roll,__deg  hding,_true  \\\n",
       "0         0.05025      0.08962      2.50369      0.02244     92.61546   \n",
       "1         0.14557      0.13320      2.78831      0.09394     92.62069   \n",
       "2         0.24257      0.15175      3.15759      0.17618     92.62554   \n",
       "3         0.32532      0.15559      3.47054      0.23833     92.62866   \n",
       "4         0.41103      0.15037      3.77623      0.29061     92.62982   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "7848    677.01807    102.64950      5.03510    -15.52756     92.21129   \n",
       "7849    677.11859    102.61120      5.03769    -15.75969     91.90834   \n",
       "7850    677.21912    102.57314      5.04044    -15.98804     91.60071   \n",
       "7851    677.31958    102.53516      5.04336    -16.21258     91.28848   \n",
       "7852    677.45129    102.48391      5.04739    -16.50119     90.87262   \n",
       "\n",
       "      __lat,__deg  __lon,__deg  ___CG,ftMSL  ____X,____m  ____Y,____m  \\\n",
       "0        45.72394   -122.55013    292.82214  35021.74609    -56.05212   \n",
       "1        45.72394   -122.55013    292.83615  35021.74219    -56.04783   \n",
       "2        45.72394   -122.55013    292.83878  35021.73438    -56.04699   \n",
       "3        45.72394   -122.55013    292.83459  35021.72656    -56.04823   \n",
       "4        45.72394   -122.55013    292.82932  35021.72266    -56.04979   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "7848     46.76450   -122.64340  10524.41309  27253.54688   3081.13818   \n",
       "7849     46.76450   -122.64333  10525.20117  27258.84961   3081.35693   \n",
       "7850     46.76449   -122.64326  10525.98730  27264.15039   3081.57471   \n",
       "7851     46.76449   -122.64320  10526.76953  27269.45117   3081.79126   \n",
       "7852     46.76449   -122.64310  10527.79102  27276.39258   3082.07373   \n",
       "\n",
       "      ____Z,____m  ___vX,__m/s  ___vY,__m/s  ___vZ,__m/s  _elev,stick  \\\n",
       "0    -24987.36914     -0.01215      0.05113      0.00660      0.00000   \n",
       "1    -24987.36719     -0.06101      0.03080      0.01416      0.00000   \n",
       "2    -24987.36719     -0.07731     -0.00651      0.01524      0.00000   \n",
       "3    -24987.36523     -0.07660     -0.01822      0.01317      0.00000   \n",
       "4    -24987.36523     -0.07464     -0.01758      0.00869      0.00000   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "7848 -29478.54102     52.76324      2.18193      2.32113      0.01481   \n",
       "7849 -29478.32422     52.75458      2.17173      2.05556      0.01505   \n",
       "7850 -29478.13281     52.74484      2.16175      1.78573      0.01529   \n",
       "7851 -29477.96875     52.73388      2.15198      1.51168      0.01552   \n",
       "7852 -29477.79492     52.71768      2.13947      1.14636      0.01582   \n",
       "\n",
       "      ailrn,stick  ruddr,stick  thro1,engin  \n",
       "0         0.00000      0.00000          0.0  \n",
       "1         0.00000      0.00000          0.0  \n",
       "2         0.00000      0.00000          0.0  \n",
       "3         0.00000      0.00000          0.0  \n",
       "4         0.00000      0.00000          0.0  \n",
       "...           ...          ...          ...  \n",
       "7848     -0.03281     -0.00584          1.0  \n",
       "7849     -0.03179     -0.00577          1.0  \n",
       "7850     -0.03097     -0.00570          1.0  \n",
       "7851     -0.02800     -0.00564          1.0  \n",
       "7852     -0.02780     -0.00559          1.0  \n",
       "\n",
       "[7853 rows x 18 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#relevent columes\n",
    "\n",
    "relevent_features = ['_totl,_time','Vtrue,_ktgs','pitch,__deg','_roll,__deg','hding,_true','__lat,__deg','__lon,__deg','___CG,ftMSL','____X,____m','____Y,____m','____Z,____m','___vX,__m/s','___vY,__m/s','___vZ,__m/s'\n",
    "                     ,'_elev,stick','ailrn,stick','ruddr,stick','thro1,engin'\n",
    "]\n",
    "\n",
    "train_data = pd.read_csv('data/Data2.csv', skiprows=1)\n",
    "train_data = train_data.dropna(axis=1, how='all')\n",
    "train_data = train_data[relevent_features]\n",
    "train_data\n",
    "\n",
    "val_data = pd.read_csv('data/Data3.csv', skiprows=1)\n",
    "val_data = val_data.dropna(axis=1, how='all')\n",
    "val_data = val_data[relevent_features]\n",
    "val_data\n",
    "\n",
    "test_data = pd.read_csv('data/Data4.csv', skiprows=1)\n",
    "test_data = train_data.dropna(axis=1, how='all')\n",
    "test_data = train_data[relevent_features]\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATING A MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlightDataset(Dataset):\n",
    "    def __init__(self, df, seq_len):\n",
    "        # Keeping only the relevant features\n",
    "        relevant_features = ['_totl,_time', 'Vtrue,_ktgs', 'pitch,__deg', '_roll,__deg', 'hding,_true', '__lat,__deg', '__lon,__deg', '___CG,ftMSL', '____X,____m', '____Y,____m', '____Z,____m', '___vX,__m/s', '___vY,__m/s', '___vZ,__m/s', '_elev,stick', 'ailrn,stick', 'ruddr,stick', 'thro1,engin']\n",
    "        \n",
    "        self.df = df[relevant_features].copy()  # Use copy to avoid modifying the original DataFrame\n",
    "\n",
    "        # Changing the names of the features for easier use\n",
    "        self.df.columns = ['time', 'vt', 'pitch', 'roll', 'hding', 'lat', 'lon', 'alt', 'x', 'y', 'z', 'vx', 'vy', 'vz', 'elev_stick', 'ailrn_stick', 'ruddr_stick', 'throttle']\n",
    "        \n",
    "        # Instantiate the StandardScaler\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "        # Fit and transform the data\n",
    "        self.df = pd.DataFrame(self.scaler.fit_transform(self.df), columns=self.df.columns)\n",
    "        \n",
    "        # Define sequence length\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        # Making the length shorter by seq_len so we always have a next_state\n",
    "        return len(self.df) - self.seq_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Current state is the sequence of states from idx to idx + seq_len\n",
    "        current_state = self.df.iloc[idx:idx + self.seq_len].values.astype(float)\n",
    "        # Next state is the state at idx + seq_len\n",
    "        next_state = self.df.iloc[idx + self.seq_len][['lat', 'lon', 'alt', 'pitch', 'roll', 'hding', 'vx', 'vy', 'vz']].values.astype(float)\n",
    "\n",
    "        return torch.tensor(current_state, dtype=torch.float32), torch.tensor(next_state, dtype=torch.float32)\n",
    "    \n",
    "    def inverse_transform(self, data):\n",
    "        return self.scaler.inverse_transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlightLSTM(pl.LightningModule):\n",
    "    def __init__(self,input_dim,hidden_dim,num_layers,output_dim,lr=0.001):\n",
    "        super(FlightLSTM,self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim,hidden_dim,num_layers,batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.lr = lr\n",
    "        self.criterion = nn.MSELoss(reduction='none')\n",
    "\n",
    "        self.training_step_outputs = []\n",
    "        self.validation_step_outputs = []\n",
    "        self.test_step_outputs = []\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out,_ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "    def compute_metrics(self, y_true, y_pred):\n",
    "        mse = np.mean((y_true - y_pred) ** 2, axis=0)\n",
    "        mae = np.mean(np.abs(y_true - y_pred), axis=0)\n",
    "        return mse, mae\n",
    "    \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        x, y = batch\n",
    "        output = self(x)\n",
    "        loss = self.criterion(output, y).mean()\n",
    "        self.log(\"train/batch/loss\", loss, prog_bar=False)\n",
    "\n",
    "        y_true = y.cpu().detach().numpy()\n",
    "        y_pred = output.cpu().detach().numpy()\n",
    "\n",
    "        mse, mae = self.compute_metrics(y_true, y_pred)\n",
    "\n",
    "        for i, feature in enumerate(['lat', 'lon', 'alt', 'pitch', 'roll', 'hding', 'vx', 'vy', 'vz']):\n",
    "            self.log(f\"train/batch/mse_{feature}\", mse[i], prog_bar=False)\n",
    "            self.log(f\"train/batch/mae_{feature}\", mae[i], prog_bar=False)\n",
    "\n",
    "        self.training_step_outputs.append({\"loss\": loss, \"mse\": mse, \"mae\": mae, \"y_true\": y_true, \"y_pred\": y_pred})\n",
    "\n",
    "        return {\"loss\": loss, \"mse\": mse, \"mae\": mae}\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        loss = np.array([output[\"loss\"].detach().cpu().numpy() for output in self.training_step_outputs])\n",
    "        mse = np.vstack([output[\"mse\"] for output in self.training_step_outputs])\n",
    "        mae = np.vstack([output[\"mae\"] for output in self.training_step_outputs])\n",
    "\n",
    "        y_true_all = np.vstack([output[\"y_true\"] for output in self.training_step_outputs])\n",
    "        y_pred_all = np.vstack([output[\"y_pred\"] for output in self.training_step_outputs])\n",
    "\n",
    "        mse_all = np.mean(mse, axis=0)\n",
    "        mae_all = np.mean(mae, axis=0)\n",
    "        r2_all = r2_score(y_true_all, y_pred_all)\n",
    "\n",
    "        self.log(\"train/epoch/loss\", loss.mean())  # Log training epoch loss\n",
    "        for i, feature in enumerate(['lat', 'lon', 'alt', 'pitch', 'roll', 'hding', 'vx', 'vy', 'vz']):\n",
    "            self.log(f\"train/epoch/mse_{feature}\", mse_all[i])  # Log training epoch MSE for each feature\n",
    "            self.log(f\"train/epoch/mae_{feature}\", mae_all[i])  # Log training epoch MAE for each feature\n",
    "        self.log(\"train/epoch/r2\", r2_all)  # Log training epoch R²\n",
    "\n",
    "        print(\"Training Epoch End: Loss:\", loss.mean(), \"MSE:\", mse_all, \"MAE:\", mae_all, \"R²:\", r2_all)  # Debugging print\n",
    "    \n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        output = self(x)\n",
    "        loss = self.criterion(output, y).mean()\n",
    "\n",
    "        y_true = y.cpu().detach().numpy()\n",
    "        y_pred = output.cpu().detach().numpy()\n",
    "\n",
    "        mse, mae = self.compute_metrics(y_true, y_pred)\n",
    "\n",
    "        for i, feature in enumerate(['lat', 'lon', 'alt', 'pitch', 'roll', 'hding', 'vx', 'vy', 'vz']):\n",
    "            self.log(f\"val/batch/mse_{feature}\", mse[i], prog_bar=False)\n",
    "            self.log(f\"val/batch/mae_{feature}\", mae[i], prog_bar=False)\n",
    "\n",
    "        self.validation_step_outputs.append({\"loss\": loss, \"mse\": mse, \"mae\": mae, \"y_true\": y_true, \"y_pred\": y_pred})\n",
    "\n",
    "        return {\"loss\": loss, \"mse\": mse, \"mae\": mae}\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        loss = np.array([output[\"loss\"].detach().cpu().numpy() for output in self.validation_step_outputs])\n",
    "        mse = np.vstack([output[\"mse\"] for output in self.validation_step_outputs])\n",
    "        mae = np.vstack([output[\"mae\"] for output in self.validation_step_outputs])\n",
    "\n",
    "        y_true_all = np.vstack([output[\"y_true\"] for output in self.validation_step_outputs])\n",
    "        y_pred_all = np.vstack([output[\"y_pred\"] for output in self.validation_step_outputs])\n",
    "\n",
    "        mse_all = np.mean(mse, axis=0)\n",
    "        mae_all = np.mean(mae, axis=0)\n",
    "        r2_all = r2_score(y_true_all, y_pred_all)\n",
    "\n",
    "        self.log(\"val/epoch/loss\", loss.mean())  # Log validation epoch loss\n",
    "        for i, feature in enumerate(['lat', 'lon', 'alt', 'pitch', 'roll', 'hding', 'vx', 'vy', 'vz']):\n",
    "            self.log(f\"val/epoch/mse_{feature}\", mse_all[i])  # Log validation epoch MSE for each feature\n",
    "            self.log(f\"val/epoch/mae_{feature}\", mae_all[i])  # Log validation epoch MAE for each feature\n",
    "        self.log(\"val/epoch/r2\", r2_all)  # Log validation epoch R²\n",
    "\n",
    "        print(\"Validation Epoch End: Loss:\", loss.mean(), \"MSE:\", mse_all, \"MAE:\", mae_all, \"R²:\", r2_all)  # Debugging print\n",
    "\n",
    "        self.validation_step_outputs.clear()  # free memory\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        output = self(x)\n",
    "        loss = self.criterion(output, y).mean()\n",
    "\n",
    "        y_true = y.cpu().detach().numpy()\n",
    "        y_pred = output.cpu().detach().numpy()\n",
    "\n",
    "        mse, mae = self.compute_metrics(y_true, y_pred)\n",
    "\n",
    "        for i, feature in enumerate(['lat', 'lon', 'alt', 'pitch', 'roll', 'hding', 'vx', 'vy', 'vz']):\n",
    "            self.log(f\"test/batch/mse_{feature}\", mse[i], prog_bar=False)\n",
    "            self.log(f\"test/batch/mae_{feature}\", mae[i], prog_bar=False)\n",
    "\n",
    "        self.test_step_outputs.append({\"loss\": loss, \"mse\": mse, \"mae\": mae, \"y_true\": y_true, \"y_pred\": y_pred})\n",
    "\n",
    "        return {\"loss\": loss, \"mse\": mse, \"mae\": mae}\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        loss = np.array([output[\"loss\"].detach().cpu().numpy() for output in self.test_step_outputs])\n",
    "        mse = np.vstack([output[\"mse\"] for output in self.test_step_outputs])\n",
    "        mae = np.vstack([output[\"mae\"] for output in self.test_step_outputs])\n",
    "\n",
    "        y_true_all = np.vstack([output[\"y_true\"] for output in self.test_step_outputs])\n",
    "        y_pred_all = np.vstack([output[\"y_pred\"] for output in self.test_step_outputs])\n",
    "\n",
    "        mse_all = np.mean(mse, axis=0)\n",
    "        mae_all = np.mean(mae, axis=0)\n",
    "        r2_all = r2_score(y_true_all, y_pred_all)\n",
    "\n",
    "        self.log(\"test/epoch/loss\", loss.mean())  # Log test epoch loss\n",
    "        for i, feature in enumerate(['lat', 'lon', 'alt', 'pitch', 'roll', 'hding', 'vx', 'vy', 'vz']):\n",
    "            self.log(f\"test/epoch/mse_{feature}\", mse_all[i])  # Log test epoch MSE for each feature\n",
    "            self.log(f\"test/epoch/mae_{feature}\", mae_all[i])  # Log test epoch MAE for each feature\n",
    "        self.log(\"test/epoch/r2\", r2_all)  # Log test epoch R²\n",
    "\n",
    "        print(\"Test Epoch End: Loss:\", loss.mean(), \"MSE:\", mse_all, \"MAE:\", mae_all, \"R²:\", r2_all)  # Debugging print\n",
    "\n",
    "        self.test_step_outputs.clear()  # free memory\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "def seed_everything(seed=42):\n",
    "    # random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    pl.seed_everything(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set the seed\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequance_length = 50\n",
    "train_dataset = FlightDataset(train_data, sequance_length)\n",
    "val_dataset = FlightDataset(val_data, sequance_length)\n",
    "test_dataset = FlightDataset(test_data, sequance_length)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "neptune_logger = NeptuneLogger(\n",
    "    api_key=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI0YTk3YWUxOS1lOWY2LTQ4NzUtOTMzMC00MDExYzA0N2UwNzAifQ==\",\n",
    "    project=\"peridan/PINN1\",\n",
    "    tags=[\"notebook\"],\n",
    "    log_model_checkpoints=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "[neptune] [warning] NeptuneWarning: The following monitoring options are disabled by default in interactive sessions: 'capture_stdout', 'capture_stderr', 'capture_traceback', and 'capture_hardware_metrics'. To enable them, set each parameter to 'True' when initializing the run. The monitoring will continue until you call run.stop() or the kernel stops. Also note: Your source files can only be tracked if you pass the path(s) to the 'source_code' argument. For help, see the Neptune docs: https://docs.neptune.ai/logging/source_code/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/peridan/PINN1/e/PIN-24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type    | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | lstm      | LSTM    | 207 K  | train\n",
      "1 | fc        | Linear  | 1.2 K  | train\n",
      "2 | criterion | MSELoss | 0      | train\n",
      "----------------------------------------------\n",
      "209 K     Trainable params\n",
      "0         Non-trainable params\n",
      "209 K     Total params\n",
      "0.836     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 15.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\anaconda3\\envs\\PinnProject\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch End: Loss: 0.5802578 MSE: [5.9525895e-01 1.5491903e+00 1.9218655e+00 9.4031505e-03 1.6895144e-03\n",
      " 6.5888023e-01 4.4193044e-01 1.0204224e-02 3.3897653e-02] MAE: [0.7715303  1.2446647  1.3863138  0.09696789 0.04110367 0.81171435\n",
      " 0.6647785  0.10101594 0.18411314] R²: -5542882997044.143\n",
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\anaconda3\\envs\\PinnProject\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 244/244 [00:05<00:00, 45.49it/s, v_num=N-24]Validation Epoch End: Loss: 1.0490841 MSE: [0.7709667  2.375589   0.6587878  0.87719953 1.0060437  0.7479808\n",
      " 1.1312435  0.8183123  1.0556326 ] MAE: [0.6877934 1.3515825 0.6948146 0.7462994 0.5602547 0.6892772 0.9693329\n",
      " 0.5704604 0.770847 ] R²: -0.04643934329710672\n",
      "Epoch 0: 100%|██████████| 244/244 [00:10<00:00, 23.96it/s, v_num=N-24]Training Epoch End: Loss: 0.6309842 MSE: [0.14942607 0.16545261 0.16151041 0.88579595 1.0253278  0.53970027\n",
      " 0.75044584 0.9859783  1.0152224 ] MAE: [0.15629618 0.2258245  0.21474294 0.45924625 0.56418025 0.46565542\n",
      " 0.5712329  0.40513313 0.58509964] R²: 0.34017969415469484\n",
      "Epoch 1:  89%|████████▉ | 218/244 [00:05<00:00, 42.90it/s, v_num=N-24][neptune] [error  ] Error occurred during asynchronous operation processing: X-coordinates (step) must be strictly increasing for series attribute: training/epoch. Invalid point: 243.0\n",
      "Epoch 1: 100%|██████████| 244/244 [00:05<00:00, 43.32it/s, v_num=N-24]Validation Epoch End: Loss: 0.8241185 MSE: [0.59439784 2.1540227  0.50992393 0.73328    0.6484522  0.46054134\n",
      " 0.42461327 0.8026435  1.089191  ] MAE: [0.58480614 1.2830303  0.6176548  0.6517588  0.49148643 0.50168467\n",
      " 0.53198534 0.5439022  0.8382989 ] R²: 0.17862469896431513\n",
      "Epoch 1: 100%|██████████| 244/244 [00:10<00:00, 24.16it/s, v_num=N-24]Training Epoch End: Loss: 0.5456832 MSE: [0.14336185 0.1467472  0.16381873 0.7671525  0.97049505 0.4378836\n",
      " 0.5880346  0.86805063 0.8256051 ] MAE: [0.1491174  0.21102633 0.2222329  0.42626712 0.5581388  0.41208106\n",
      " 0.49060166 0.39072937 0.5216572 ] R²: 0.4260704049079817\n",
      "Epoch 2: 100%|██████████| 244/244 [00:05<00:00, 47.65it/s, v_num=N-24][neptune] [error  ] Error occurred during asynchronous operation processing: X-coordinates (step) must be strictly increasing for series attribute: training/epoch. Invalid point: 487.0\n",
      "Validation Epoch End: Loss: 0.91938394 MSE: [0.6112651  3.1588812  0.47899964 0.46438593 1.1383198  0.5332859\n",
      " 0.44665518 0.46715593 0.97550553] MAE: [0.56811166 1.607274   0.57722855 0.5795309  0.84074783 0.55705017\n",
      " 0.46215895 0.43339863 0.7699622 ] R²: 0.0829049843759272\n",
      "Epoch 2: 100%|██████████| 244/244 [00:09<00:00, 25.40it/s, v_num=N-24]Training Epoch End: Loss: 0.47611898 MSE: [0.13172702 0.14971578 0.15147752 0.6684513  0.8569883  0.34696168\n",
      " 0.49978325 0.76812744 0.71183854] MAE: [0.14644073 0.21786848 0.21821804 0.38993153 0.51507473 0.3575005\n",
      " 0.44523868 0.37633678 0.47635043] R²: 0.4974487666602642\n",
      "Epoch 3:  23%|██▎       | 57/244 [00:01<00:04, 46.69it/s, v_num=N-24] [neptune] [error  ] Error occurred during asynchronous operation processing: X-coordinates (step) must be strictly increasing for series attribute: training/epoch. Invalid point: 731.0\n",
      "Epoch 3: 100%|██████████| 244/244 [00:05<00:00, 47.32it/s, v_num=N-24]Validation Epoch End: Loss: 0.96477187 MSE: [0.583185   3.7589853  0.33075222 0.2705243  0.8669157  0.8501007\n",
      " 0.39635807 0.32345334 1.3026718 ] MAE: [0.52172565 1.751506   0.47069934 0.3893806  0.77096945 0.8023957\n",
      " 0.53453434 0.38593662 0.9340035 ] R²: 0.03675247467148505\n",
      "Epoch 3: 100%|██████████| 244/244 [00:09<00:00, 24.91it/s, v_num=N-24]Training Epoch End: Loss: 0.4239341 MSE: [0.13839693 0.15883785 0.15402749 0.57787234 0.79533213 0.3005373\n",
      " 0.43653017 0.662297   0.5915754 ] MAE: [0.15478398 0.22278766 0.2210511  0.36065042 0.48749483 0.32751244\n",
      " 0.40903577 0.35538346 0.42808455] R²: 0.5482780147941543\n",
      "Epoch 4:  35%|███▍      | 85/244 [00:01<00:03, 46.71it/s, v_num=N-24][neptune] [error  ] Error occurred during asynchronous operation processing: X-coordinates (step) must be strictly increasing for series attribute: training/epoch. Invalid point: 975.0\n",
      "Epoch 4: 100%|██████████| 244/244 [00:05<00:00, 47.11it/s, v_num=N-24]Validation Epoch End: Loss: 0.7869697 MSE: [0.62608963 2.0841746  0.36877424 0.4150743  0.6838153  0.69014966\n",
      " 0.3298026  0.5385684  1.3462784 ] MAE: [0.59585315 1.3123597  0.540144   0.49931064 0.60858214 0.6915202\n",
      " 0.47266674 0.4605633  0.8767761 ] R²: 0.21573436470844826\n",
      "Epoch 4: 100%|██████████| 244/244 [00:09<00:00, 24.82it/s, v_num=N-24]Training Epoch End: Loss: 0.37587285 MSE: [0.1349315  0.15365122 0.14215526 0.5033758  0.72105783 0.2627882\n",
      " 0.38898316 0.57866496 0.49724728] MAE: [0.15441813 0.21911909 0.20967667 0.33727396 0.45677415 0.30205077\n",
      " 0.38130808 0.33762956 0.3856682 ] R²: 0.5973584174312639\n",
      "Epoch 5:  45%|████▌     | 111/244 [00:02<00:02, 47.24it/s, v_num=N-24][neptune] [error  ] Error occurred during asynchronous operation processing: X-coordinates (step) must be strictly increasing for series attribute: training/epoch. Invalid point: 1219.0\n",
      "Epoch 5: 100%|██████████| 244/244 [00:05<00:00, 44.42it/s, v_num=N-24]Validation Epoch End: Loss: 0.7592714 MSE: [0.3606231  2.9867437  0.25971043 0.49780133 0.8144245  0.5613371\n",
      " 0.26931193 0.57313657 0.51035213] MAE: [0.3579138  1.5246838  0.42803022 0.5216817  0.7662608  0.613046\n",
      " 0.3756487  0.5040946  0.61383015] R²: 0.24159785275046008\n",
      "Epoch 5: 100%|██████████| 244/244 [00:10<00:00, 22.49it/s, v_num=N-24]Training Epoch End: Loss: 0.3376726 MSE: [0.13163036 0.14788933 0.13232018 0.44787472 0.6440193  0.23889542\n",
      " 0.346374   0.51709986 0.4329502 ] MAE: [0.15110978 0.21560153 0.20030619 0.3192135  0.4228591  0.28283206\n",
      " 0.356271   0.31945586 0.35806358] R²: 0.6364833502457508\n",
      "Epoch 6:  29%|██▊       | 70/244 [00:01<00:04, 37.89it/s, v_num=N-24] [neptune] [error  ] Error occurred during asynchronous operation processing: X-coordinates (step) must be strictly increasing for series attribute: training/epoch. Invalid point: 1463.0\n",
      "Epoch 6: 100%|██████████| 244/244 [00:06<00:00, 38.85it/s, v_num=N-24]Validation Epoch End: Loss: 0.63772994 MSE: [0.42653406 2.2436986  0.3967579  0.2675991  0.40136284 0.47603032\n",
      " 0.29575866 0.36221722 0.86961126] MAE: [0.4104322  1.3092697  0.5169004  0.40615058 0.43997762 0.54201126\n",
      " 0.4271606  0.42146608 0.70178384] R²: 0.36426727603558257\n",
      "Epoch 6: 100%|██████████| 244/244 [00:11<00:00, 21.08it/s, v_num=N-24]Training Epoch End: Loss: 0.31029958 MSE: [0.12528343 0.14254382 0.12403349 0.4113361  0.601813   0.21539067\n",
      " 0.31177822 0.47399935 0.3865186 ] MAE: [0.14659207 0.21126084 0.19294022 0.30975276 0.40867656 0.2633671\n",
      " 0.33298084 0.30931133 0.33433   ] R²: 0.6651429342560591\n",
      "Epoch 7:   9%|▉         | 22/244 [00:00<00:05, 39.71it/s, v_num=N-24] [neptune] [error  ] Error occurred during asynchronous operation processing: X-coordinates (step) must be strictly increasing for series attribute: training/epoch. Invalid point: 1707.0\n",
      "Epoch 7: 100%|██████████| 244/244 [00:06<00:00, 39.03it/s, v_num=N-24]Validation Epoch End: Loss: 0.6956519 MSE: [0.51178265 2.2687812  0.26698118 0.41674802 0.4662617  0.5063916\n",
      " 0.72379076 0.38084176 0.71928877] MAE: [0.49470156 1.3245617  0.41699463 0.5619663  0.5739915  0.45351923\n",
      " 0.6461657  0.49697605 0.7108928 ] R²: 0.30606758492431435\n",
      "Epoch 7: 100%|██████████| 244/244 [00:11<00:00, 21.21it/s, v_num=N-24]Training Epoch End: Loss: 0.28807658 MSE: [0.12032918 0.14069653 0.11826202 0.38087484 0.55653214 0.1964722\n",
      " 0.283895   0.43964234 0.3559855 ] MAE: [0.14197908 0.21041493 0.18800223 0.2984634  0.389858   0.2489937\n",
      " 0.3155055  0.2991561  0.32161185] R²: 0.6882720939294014\n",
      "Epoch 8:  76%|███████▌  | 186/244 [00:04<00:01, 39.38it/s, v_num=N-24][neptune] [error  ] Error occurred during asynchronous operation processing: X-coordinates (step) must be strictly increasing for series attribute: training/epoch. Invalid point: 1951.0\n",
      "Epoch 8: 100%|██████████| 244/244 [00:06<00:00, 39.23it/s, v_num=N-24]Validation Epoch End: Loss: 0.6466199 MSE: [0.5840656  2.0638175  0.17977893 0.34918165 0.6034453  0.4861317\n",
      " 0.33138415 0.50391465 0.71786016] MAE: [0.5367553  1.2690811  0.3610487  0.42024225 0.53710556 0.5015525\n",
      " 0.4460531  0.43206343 0.6097551 ] R²: 0.3558564848628643\n",
      "Epoch 8: 100%|██████████| 244/244 [00:11<00:00, 21.31it/s, v_num=N-24]Training Epoch End: Loss: 0.27070063 MSE: [0.11480617 0.1332171  0.11317652 0.35215876 0.5342979  0.1856243\n",
      " 0.26535764 0.40861323 0.32905465] MAE: [0.13902478 0.20517886 0.18288282 0.28650153 0.37817693 0.23984908\n",
      " 0.30470443 0.2898713  0.30707812] R²: 0.7067216732515864\n",
      "Epoch 9:  57%|█████▋    | 139/244 [00:03<00:02, 38.36it/s, v_num=N-24][neptune] [error  ] Error occurred during asynchronous operation processing: X-coordinates (step) must be strictly increasing for series attribute: training/epoch. Invalid point: 2195.0\n",
      "Epoch 9: 100%|██████████| 244/244 [00:06<00:00, 39.24it/s, v_num=N-24]Validation Epoch End: Loss: 0.5896311 MSE: [0.46445715 1.8949507  0.32088506 0.27627942 0.24837546 0.4247767\n",
      " 0.5079664  0.52644616 0.6425422 ] MAE: [0.46699256 1.1933467  0.43833926 0.40804303 0.364023   0.48530647\n",
      " 0.5733477  0.5350429  0.6397947 ] R²: 0.41187195336001103\n",
      "Epoch 9: 100%|██████████| 244/244 [00:11<00:00, 20.69it/s, v_num=N-24]Training Epoch End: Loss: 0.25644475 MSE: [0.11022823 0.12708358 0.10816444 0.33536133 0.50704855 0.17457578\n",
      " 0.25062704 0.38993758 0.30497658] MAE: [0.13624184 0.20027001 0.17805889 0.27941126 0.3645476  0.23019662\n",
      " 0.29347172 0.2816799  0.29360226] R²: 0.721905177308669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 244/244 [00:11<00:00, 20.42it/s, v_num=N-24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\ADMIN\\anaconda3\\envs\\PinnProject\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0:  31%|███       | 76/244 [00:01<00:04, 38.34it/s][neptune] [error  ] Error occurred during asynchronous operation processing: X-coordinates (step) must be strictly increasing for series attribute: training/epoch. Invalid point: 2439.0\n",
      "Testing DataLoader 0: 100%|██████████| 244/244 [00:06<00:00, 39.46it/s]Test Epoch End: Loss: 0.14406982 MSE: [0.0831078  0.09268803 0.07167563 0.23067963 0.2752669  0.11534791\n",
      " 0.15004247 0.18228169 0.09553844] MAE: [0.18642491 0.23695542 0.18094088 0.3657271  0.3260155  0.22495574\n",
      " 0.26355052 0.2976932  0.24105343] R²: 0.8399912555252496\n",
      "Testing DataLoader 0: 100%|██████████| 244/244 [00:06<00:00, 39.21it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "   test/batch/mae_alt       0.18095342814922333\n",
      "  test/batch/mae_hding      0.22509358823299408\n",
      "   test/batch/mae_lat       0.18650038540363312\n",
      "   test/batch/mae_lon       0.2370768040418625\n",
      "  test/batch/mae_pitch      0.3659030497074127\n",
      "   test/batch/mae_roll      0.3261619508266449\n",
      "    test/batch/mae_vx       0.2636970579624176\n",
      "    test/batch/mae_vy       0.2977556586265564\n",
      "    test/batch/mae_vz       0.24117615818977356\n",
      "   test/batch/mse_alt       0.07170486450195312\n",
      "  test/batch/mse_hding      0.11542173475027084\n",
      "   test/batch/mse_lat       0.08315801620483398\n",
      "   test/batch/mse_lon       0.09274542331695557\n",
      "  test/batch/mse_pitch      0.2308221012353897\n",
      "   test/batch/mse_roll      0.2754359245300293\n",
      "    test/batch/mse_vx       0.15013781189918518\n",
      "    test/batch/mse_vy       0.18237222731113434\n",
      "    test/batch/mse_vz       0.09559757262468338\n",
      "     test/epoch/loss        0.1440698206424713\n",
      "   test/epoch/mae_alt       0.1809408813714981\n",
      "  test/epoch/mae_hding      0.2249557375907898\n",
      "   test/epoch/mae_lat       0.18642491102218628\n",
      "   test/epoch/mae_lon       0.2369554191827774\n",
      "  test/epoch/mae_pitch      0.36572709679603577\n",
      "   test/epoch/mae_roll      0.32601550221443176\n",
      "    test/epoch/mae_vx       0.2635505199432373\n",
      "    test/epoch/mae_vy       0.2976931929588318\n",
      "    test/epoch/mae_vz       0.24105343222618103\n",
      "   test/epoch/mse_alt       0.0716756284236908\n",
      "  test/epoch/mse_hding      0.11534790694713593\n",
      "   test/epoch/mse_lat       0.08310779929161072\n",
      "   test/epoch/mse_lon       0.09268803149461746\n",
      "  test/epoch/mse_pitch      0.23067963123321533\n",
      "   test/epoch/mse_roll      0.2752668857574463\n",
      "    test/epoch/mse_vx       0.15004247426986694\n",
      "    test/epoch/mse_vy       0.18228168785572052\n",
      "    test/epoch/mse_vz       0.09553844481706619\n",
      "      test/epoch/r2         0.8399912714958191\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 40 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 40 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/peridan/PINN1/e/PIN-24/metadata\n"
     ]
    }
   ],
   "source": [
    "seed_everything()\n",
    "input_dim = len(train_data.columns)\n",
    "hidden_dim = 128\n",
    "num_layers = 2\n",
    "output_dim = 9\n",
    "model = FlightLSTM(input_dim, hidden_dim, num_layers, output_dim)\n",
    "trainer = pl.Trainer(\n",
    "    logger = neptune_logger,\n",
    "    max_epochs=10\n",
    "    )\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "trainer.test(model, test_loader)\n",
    "neptune_logger.experiment.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "optimizer got an empty parameter list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbaseline_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\PinnProject\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:543\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 543\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\PinnProject\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\PinnProject\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:579\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    573\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    575\u001b[0m     ckpt_path,\n\u001b[0;32m    576\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    577\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    578\u001b[0m )\n\u001b[1;32m--> 579\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    581\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\PinnProject\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:962\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    959\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger_connector\u001b[38;5;241m.\u001b[39mreset_metrics()\n\u001b[0;32m    961\u001b[0m \u001b[38;5;66;03m# strategy will configure model and move it to the device\u001b[39;00m\n\u001b[1;32m--> 962\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[38;5;66;03m# hook\u001b[39;00m\n\u001b[0;32m    965\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;241m==\u001b[39m TrainerFn\u001b[38;5;241m.\u001b[39mFITTING:\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\PinnProject\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:158\u001b[0m, in \u001b[0;36mStrategy.setup\u001b[1;34m(self, trainer)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_model(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;241m==\u001b[39m TrainerFn\u001b[38;5;241m.\u001b[39mFITTING:\n\u001b[1;32m--> 158\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_optimizers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup_precision_plugin()\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;241m==\u001b[39m TrainerFn\u001b[38;5;241m.\u001b[39mFITTING:\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\PinnProject\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:138\u001b[0m, in \u001b[0;36mStrategy.setup_optimizers\u001b[1;34m(self, trainer)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates optimizers and schedulers.\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \n\u001b[0;32m    133\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;124;03m    trainer: the Trainer, these optimizers should be connected to\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler_configs \u001b[38;5;241m=\u001b[39m \u001b[43m_init_optimizers_and_lr_schedulers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\PinnProject\\lib\\site-packages\\pytorch_lightning\\core\\optimizer.py:179\u001b[0m, in \u001b[0;36m_init_optimizers_and_lr_schedulers\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls `LightningModule.configure_optimizers` and parses and validates the output.\"\"\"\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m call\n\u001b[1;32m--> 179\u001b[0m optim_conf \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfigure_optimizers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpl_module\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optim_conf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    182\u001b[0m     rank_zero_warn(\n\u001b[0;32m    183\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    184\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\PinnProject\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:159\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[1;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m hook_name\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 159\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m    162\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "Cell \u001b[1;32mIn[35], line 25\u001b[0m, in \u001b[0;36mBaselineModel.configure_optimizers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfigure_optimizers\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# Return a dummy optimizer\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSGD\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\PinnProject\\lib\\site-packages\\torch\\optim\\sgd.py:27\u001b[0m, in \u001b[0;36mSGD.__init__\u001b[1;34m(self, params, lr, momentum, dampening, weight_decay, nesterov, maximize, foreach, differentiable, fused)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nesterov \u001b[38;5;129;01mand\u001b[39;00m (momentum \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dampening \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNesterov momentum requires a momentum and zero dampening\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step_supports_amp_scaling \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\PinnProject\\lib\\site-packages\\torch\\optim\\optimizer.py:279\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[1;34m(self, params, defaults)\u001b[0m\n\u001b[0;32m    277\u001b[0m param_groups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(params)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(param_groups) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer got an empty parameter list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(param_groups[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    281\u001b[0m     param_groups \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: param_groups}]\n",
      "\u001b[1;31mValueError\u001b[0m: optimizer got an empty parameter list"
     ]
    }
   ],
   "source": [
    "baseline_model = BaselineModel()\n",
    "\n",
    "# Initialize the trainer\n",
    "trainer = pl.Trainer(max_epochs=10)\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(baseline_model, train_loader, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PinnProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
